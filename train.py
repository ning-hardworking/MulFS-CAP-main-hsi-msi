import os
import time
from pathlib import Path

import math
import numpy as np
import torch
import torch.nn.functional as F
import torch.utils.data as data
import torchvision
import scipy.io as sio
from PIL import Image
from torch.cuda.amp import autocast, GradScaler

from utils.utils import save_img
from tqdm import tqdm

import args
from loss import loss as Loss
from model import model
from utils import utils

# å…¨å±€å¸¸é‡å®šä¹‰
model_name = "MulFS-CAP-HSI-MSI"
device_id = "0"


def adjust_learning_rate(optimizer, epoch_count):
    lr = args.args.LR + 0.5 * (args.args.LR_target - args.args.LR) * (
            1 + math.cos((epoch_count - args.args.Warm_epoch) / (args.args.Epoch - args.args.Warm_epoch) * math.pi))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


def warmup_learning_rate(optimizer, epoch_count):
    lr = epoch_count * ((args.args.LR_target - args.args.LR) / args.args.Warm_epoch) + args.args.LR
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


class TrainDataset(data.Dataset):
    def __init__(self, hsi_dir, msi_dir, gt_dir,
                 hsi_deformed_dir, msi_deformed_dir, gt_deformed_dir,
                 transform=None):
        super(TrainDataset, self).__init__()

        # Pair 1: åŸå§‹é…å‡†æ•°æ®
        self.hsi_paths = self.find_mat_files(hsi_dir)
        self.msi_paths = self.find_mat_files(msi_dir)
        self.gt_paths = self.find_mat_files(gt_dir)

        # Pair 2: å½¢å˜é…å‡†æ•°æ®
        self.hsi_d_paths = self.find_mat_files(hsi_deformed_dir)
        self.msi_d_paths = self.find_mat_files(msi_deformed_dir)
        self.gt_d_paths = self.find_mat_files(gt_deformed_dir)

        assert len(self.hsi_paths) == len(self.hsi_d_paths), \
            f"é…å¯¹æ•°æ®æ•°é‡ä¸ä¸€è‡´: Pair1={len(self.hsi_paths)}, Pair2={len(self.hsi_d_paths)}"

        self.transform = transform
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ:")
        print(f"   - Pair 1 (åŸå§‹é…å‡†): {len(self.hsi_paths)} å¯¹æ ·æœ¬")
        print(f"   - Pair 2 (å½¢å˜é…å‡†): {len(self.hsi_d_paths)} å¯¹æ ·æœ¬")

    def find_mat_files(self, dir_path):
        """æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶"""
        mat_files = []
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                if file.endswith('.mat'):
                    mat_files.append(os.path.join(root, file))
        mat_files.sort()
        return mat_files

    def read_mat_image(self, path, key=None):
        """
        è¯»å–.matæ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼šè‡ªåŠ¨è¯†åˆ«é€šé“ç»´åº¦ï¼‰

        å‚æ•°:
            path: .matæ–‡ä»¶è·¯å¾„
            key: .matæ–‡ä»¶ä¸­çš„å˜é‡åï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨æŸ¥æ‰¾ï¼‰

        è¿”å›:
            torch.Tensor: shapeä¸º(C, H, W)çš„å¼ é‡
        """
        try:
            mat_data = sio.loadmat(path)

            # è‡ªåŠ¨æŸ¥æ‰¾æ•°æ®é”®ï¼ˆæ’é™¤MATLABå…ƒæ•°æ®ï¼‰
            if key is None:
                valid_keys = [k for k in mat_data.keys() if not k.startswith('__')]
                if len(valid_keys) == 0:
                    raise ValueError(f"æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®é”®: {path}")
                key = valid_keys[0]

            img = mat_data[key]  # numpyæ•°ç»„: å¯èƒ½æ˜¯ (H,W,C) æˆ– (C,H,W) æˆ–å…¶ä»–

            # ========== ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ™ºèƒ½è¯†åˆ«é€šé“ç»´åº¦ ğŸ”¥ ==========
            if img.ndim == 2:
                # 2Då›¾åƒ -> æ·»åŠ é€šé“ç»´åº¦
                img = torch.from_numpy(img).float().unsqueeze(0)  # (H, W) -> (1, H, W)

            elif img.ndim == 3:
                # 3Då›¾åƒ -> éœ€è¦è¯†åˆ«å“ªä¸ªç»´åº¦æ˜¯é€šé“
                shape = img.shape

                # ğŸ”¥ ç­–ç•¥1: æ‰¾åˆ°æœ€å°çš„ç»´åº¦ä½œä¸ºé€šé“ï¼ˆé€šå¸¸é€šé“æ•°æœ€å°ï¼‰
                min_dim_idx = np.argmin(shape)

                # ğŸ”¥ ç­–ç•¥2: éªŒè¯æ˜¯å¦ç¬¦åˆé¢„æœŸçš„é€šé“æ•° (3 æˆ– 31)
                expected_channels = [3, 31]
                channel_dim_idx = None

                for i, s in enumerate(shape):
                    if s in expected_channels:
                        channel_dim_idx = i
                        break

                # ä¼˜å…ˆä½¿ç”¨ç­–ç•¥2ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™ä½¿ç”¨ç­–ç•¥1
                if channel_dim_idx is not None:
                    target_dim = channel_dim_idx
                else:
                    target_dim = min_dim_idx

                # å°†é€šé“ç»´åº¦ç§»åˆ°ç¬¬0ä½
                img = np.moveaxis(img, source=target_dim, destination=0)
                img = torch.from_numpy(img).float()  # (C, H, W)

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒç»´åº¦: {img.ndim}Dï¼Œè·¯å¾„: {path}")

            # ========== å½’ä¸€åŒ–åˆ°[0, 1] ==========
            if img.max() > 1.0:
                img = img / img.max()

            # ========== åº”ç”¨transformï¼ˆå¦‚æœéœ€è¦resizeï¼‰==========
            if self.transform is not None:
                img = self.transform(img)

            # ========== ğŸ”¥ æœ€ç»ˆéªŒè¯ï¼šæ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»´åº¦ ğŸ”¥ ==========
            if not hasattr(self, '_first_load_done'):
                print(f"\nâœ… æ•°æ®åŠ è½½éªŒè¯ (æ–‡ä»¶: {os.path.basename(path)}):")
                print(f"   åŸå§‹shape: {mat_data[key].shape}")
                print(f"   å¤„ç†å:    {img.shape}")
                print(f"   é¢„æœŸæ ¼å¼:  (C, H, W) å…¶ä¸­ Câˆˆ{3, 31}, H,Wâˆˆ{16, 512}\n")
                self._first_load_done = True

            return img

        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {path}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            raise

    def __getitem__(self, index):
        # Pair 1: åŸå§‹é…å‡†å¯¹
        hsi_1 = self.read_mat_image(self.hsi_paths[index])  # (31, 16, 16)
        msi_1 = self.read_mat_image(self.msi_paths[index])  # (3, 512, 512)
        gt_1 = self.read_mat_image(self.gt_paths[index])  # (31, 512, 512)

        # Pair 2: å½¢å˜é…å‡†å¯¹
        hsi_2 = self.read_mat_image(self.hsi_d_paths[index])  # (31, 16, 16)
        msi_2 = self.read_mat_image(self.msi_d_paths[index])  # (3, 512, 512)
        gt_2 = self.read_mat_image(self.gt_d_paths[index])  # (31, 512, 512)

        return hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2

    def __len__(self):
        return len(self.hsi_paths)


# æ ¸å¿ƒï¼šæ‰€æœ‰æ‰§è¡Œé€»è¾‘å¿…é¡»åŒ…è£¹åˆ°if __name__ == '__main__'ä¸­
if __name__ == '__main__':
    # ========== åˆå§‹åŒ–ç¯å¢ƒ ==========
    os.environ['CUDA_LAUNCH_BLOCKING'] = device_id
    device = torch.device("cuda:" + device_id if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        torch.multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        pass

    # ========== åˆå§‹åŒ–ä¿å­˜ç›®å½• ==========
    now = int(time.time())
    timeArr = time.localtime(now)
    nowTime = time.strftime("%Y%m%d_%H-%M-%S", timeArr)
    save_model_dir = args.args.train_save_model_dir + "/" + nowTime + "_" + model_name + "_model"
    save_img_dir = args.args.train_save_img_dir + "/" + nowTime + "_" + model_name + "_img"
    utils.check_dir(save_model_dir)
    utils.check_dir(save_img_dir)

    # ========== æ•°æ®åŠ è½½å™¨åˆå§‹åŒ– ==========
    tf = None

    # âœ… ä¿®æ”¹æ•°æ®é›†åˆå§‹åŒ–
    dataset = TrainDataset(
        args.args.hsi_train_dir,  # Z_reconst/
        args.args.msi_train_dir,  # Y_reconst/
        args.args.gt_train_dir,  # X/
        args.args.hsi_deformed_train_dir,  # Z_deformed/
        args.args.msi_deformed_train_dir,  # Y_deformed/
        args.args.gt_deformed_train_dir,  # X_deformed/
        tf
    )

    data_iter = data.DataLoader(
        dataset=dataset,
        shuffle=True,
        batch_size=args.args.batch_size,
        num_workers=4,
        pin_memory=True,
        drop_last=True,
        multiprocessing_context=torch.multiprocessing.get_context('spawn')
    )

    iter_num = int(dataset.__len__() / args.args.batch_size)
    save_image_iter = max(1, int(iter_num / args.args.save_image_num))

    # ========== æ¨¡å‹åˆå§‹åŒ– ==========
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    Lgrad = Loss.L_Grad().to(device)
    CC = Loss.CorrelationCoefficient().to(device)
    Lcorrespondence = Loss.L_correspondence()

    # âœ… å…³é”®ä¿®å¤1: åˆ›å»ºä¸¤ä¸ªä¸åŒçš„baseæ¨¡å—
    with torch.no_grad():
        base_msi = model.base(in_channels=3)  # MSI: 3é€šé“ -> 64é€šé“
        base_hsi = model.base(in_channels=31)  # HSI: 31é€šé“ -> 64é€šé“
        hsi_MFE = model.FeatureExtractor()
        msi_MFE = model.FeatureExtractor()
        fusion_decoder = model.Decoder()
        PAFE = model.FeatureExtractor()
        decoder = model.Decoder()
        MN_hsi = model.Enhance()
        MN_msi = model.Enhance()
        HSIDP = model.DictionaryRepresentationModule()
        MSIDP = model.DictionaryRepresentationModule()
        ImageDeformation = model.ImageTransform()
        MHCSA_hsi = model.MHCSAB()
        MHCSA_msi = model.MHCSAB()
        fusion_module = model.FusionMoudle()

    # æ¨¡å‹è®­ç»ƒæ¨¡å¼+è®¾å¤‡è¿ç§»
    print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°GPU...")
    base_msi.train().to(device)
    base_hsi.train().to(device)
    hsi_MFE.train().to(device)
    msi_MFE.train().to(device)
    fusion_decoder.train().to(device)
    PAFE.train().to(device)
    decoder.train().to(device)
    HSIDP.train().to(device)
    MSIDP.train().to(device)
    MN_hsi.train().to(device)
    MN_msi.train().to(device)
    MHCSA_hsi.train().to(device)
    MHCSA_msi.train().to(device)
    fusion_module.train().to(device)

    # ========== ä¼˜åŒ–å™¨åˆå§‹åŒ– ==========
    print("âš™ï¸ æ­£åœ¨é…ç½®ä¼˜åŒ–å™¨...")
    optimizer_FE = torch.optim.Adam([
        {'params': base_msi.parameters()},  # âœ… ä¿®å¤2: åŒ…å«ä¸¤ä¸ªbase
        {'params': base_hsi.parameters()},
        {'params': hsi_MFE.parameters()},
        {'params': msi_MFE.parameters()},
        {'params': fusion_decoder.parameters()},
        {'params': PAFE.parameters()},
        {'params': decoder.parameters()},
        {'params': MN_hsi.parameters()},
        {'params': MN_msi.parameters()}
    ], lr=0.0002)

    optimizer_HSIDP = torch.optim.Adam(HSIDP.parameters(), lr=0.0008)
    optimizer_MSIDP = torch.optim.Adam(MSIDP.parameters(), lr=0.0008)
    optimizer_MHCSAhsi = torch.optim.Adam(MHCSA_hsi.parameters(), lr=args.args.LR)
    optimizer_MHCSAmsi = torch.optim.Adam(MHCSA_msi.parameters(), lr=args.args.LR)
    optimizer_FusionModule = torch.optim.Adam(fusion_module.parameters(), lr=0.0002)

    # âœ… ä¼˜åŒ–3: æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()
    print("âœ… å·²å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ï¼Œæ˜¾å­˜å ç”¨å°†å‡å°‘çº¦50%")


    # ========== è®­ç»ƒå‡½æ•°å®šä¹‰ ==========
    def train(epoch):
        """
        è®­ç»ƒå‡½æ•°
        å¤„ç†ä¸¤å¯¹é…å‡†æ•°æ®ï¼š
        - Pair 1: (hsi_1, msi_1, gt_1) - åŸå§‹é…å‡†å¯¹ï¼ˆæ¥è‡ªZ_reconst, Y_reconst, Xï¼‰
        - Pair 2: (hsi_2, msi_2, gt_2) - å½¢å˜é…å‡†å¯¹ï¼ˆæ¥è‡ªZ_deformed, Y_deformed, X_deformedï¼‰

        æ ¸å¿ƒæ€è·¯ï¼š
        1. åˆ†åˆ«æå–ä¸¤å¯¹é…å‡†æ•°æ®çš„ç‰¹å¾
        2. ç”¨Pair1çš„HSIç‰¹å¾ + Pair2çš„MSIç‰¹å¾ æ„é€ æœªé…å‡†å¯¹
        3. é€šè¿‡è·¨æ¨¡æ€å¯¹é½æ„ŸçŸ¥å­¦ä¹ å¯¹é½å…³ç³»
        4. ç”Ÿæˆæœ€ç»ˆçš„èåˆç»“æœ
        """
        epoch_loss_HSIDP = []
        epoch_loss_MSIDP = []
        epoch_loss_same = []
        epoch_loss_fusion_total = []

        for step, x in enumerate(data_iter):
            # ========== æ•°æ®åŠ è½½ï¼ˆ6ä¸ªå¼ é‡ï¼‰==========
            hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2 = [
                item.to(device, non_blocking=True) for item in x
            ]

            # æ‰“å°ç»´åº¦ï¼ˆä»…ç¬¬ä¸€ä¸ªbatchï¼‰
            if step == 0 and epoch == 0:
                print(f"\nâœ… æ•°æ®ç»´åº¦éªŒè¯:")
                print(f"   Pair 1: HSI={hsi_1.shape}, MSI={msi_1.shape}, GT={gt_1.shape}")
                print(f"   Pair 2: HSI={hsi_2.shape}, MSI={msi_2.shape}, GT={gt_2.shape}")

            # ========== ä¸Šé‡‡æ ·HSIåˆ°MSIçš„åˆ†è¾¨ç‡ ==========
            hsi_1_up = F.interpolate(
                hsi_1,
                size=(msi_1.size(2), msi_1.size(3)),
                mode='bilinear',
                align_corners=False
            )
            hsi_2_up = F.interpolate(
                hsi_2,
                size=(msi_2.size(2), msi_2.size(3)),
                mode='bilinear',
                align_corners=False
            )

            # ========== æ··åˆç²¾åº¦è®­ç»ƒ ==========
            with autocast():
                # ====================================================================
                # é˜¶æ®µ1: åŸºç¡€ç‰¹å¾æå–ï¼ˆ64é€šé“ç»Ÿä¸€ç‰¹å¾ç©ºé—´ï¼‰
                # ====================================================================
                hsi_1_base = base_hsi(hsi_1_up)  # (B, 31, 512, 512) -> (B, 64, 512, 512)
                msi_1_base = base_msi(msi_1)  # (B, 3, 512, 512)  -> (B, 64, 512, 512)
                hsi_2_base = base_hsi(hsi_2_up)  # (B, 31, 512, 512) -> (B, 64, 512, 512)
                msi_2_base = base_msi(msi_2)  # (B, 3, 512, 512)  -> (B, 64, 512, 512)

                # é‡Šæ”¾ä¸éœ€è¦çš„ä¸Šé‡‡æ ·ç»“æœ
                del hsi_1_up, hsi_2_up
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ2: æ·±å±‚ç‰¹å¾æå–ï¼ˆç”¨äºèåˆé‡å»ºï¼‰
                # ====================================================================
                # Pair 1 çš„æ·±å±‚ç‰¹å¾
                hsi_1_fe = hsi_MFE(hsi_1_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_1_fe = msi_MFE(msi_1_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                simple_fusion_f_1 = hsi_1_fe + msi_1_fe
                fusion_image_1, fusion_f_1 = fusion_decoder(simple_fusion_f_1)  # -> (B, 31, 512, 512)

                # Pair 2 çš„æ·±å±‚ç‰¹å¾
                hsi_2_fe = hsi_MFE(hsi_2_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_2_fe = msi_MFE(msi_2_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                simple_fusion_f_2 = hsi_2_fe + msi_2_fe
                fusion_image_2, fusion_f_2 = fusion_decoder(simple_fusion_f_2)  # -> (B, 31, 512, 512)

                del simple_fusion_f_1, simple_fusion_f_2
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ3: PAFEç‰¹å¾æå–ï¼ˆç”¨äºå¯¹é½æ„ŸçŸ¥ï¼‰
                # ====================================================================
                # Pair 1 çš„PAFEç‰¹å¾
                hsi_1_f = PAFE(hsi_1_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_1_f = PAFE(msi_1_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                simple_fusion_pf_1 = hsi_1_f + msi_1_f
                fusion_pimage_1, fusion_pf_1 = decoder(simple_fusion_pf_1)  # -> (B, 31, 512, 512)

                # Pair 2 çš„PAFEç‰¹å¾
                hsi_2_f = PAFE(hsi_2_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_2_f = PAFE(msi_2_base)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                simple_fusion_pf_2 = hsi_2_f + msi_2_f
                fusion_pimage_2, fusion_pf_2 = decoder(simple_fusion_pf_2)  # -> (B, 31, 512, 512)

                del simple_fusion_pf_1, simple_fusion_pf_2
                del hsi_1_base, hsi_2_base, msi_1_base, msi_2_base
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ4: æ¨¡æ€å½’ä¸€åŒ–ï¼ˆModality Normalizationï¼‰
                # ====================================================================
                hsi_1_e_f = MN_hsi(hsi_1_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_1_e_f = MN_msi(msi_1_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                hsi_2_e_f = MN_hsi(hsi_2_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                msi_2_e_f = MN_msi(msi_2_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)

                # ====================================================================
                # é˜¶æ®µ5: å­—å…¸è¡¨ç¤ºæ¨¡å—ï¼ˆDictionary Representation Moduleï¼‰
                # ç”¨å¯å­¦ä¹ çš„æ¨¡æ€å­—å…¸è¡¥å¿å•æ¨¡æ€ç‰¹å¾ç¼ºå¤±çš„ä¿¡æ¯
                # ====================================================================
                HSIDP_hsi_1_f, _ = HSIDP(hsi_1_e_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                MSIDP_msi_1_f, _ = MSIDP(msi_1_e_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                HSIDP_hsi_2_f, _ = HSIDP(hsi_2_e_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)
                MSIDP_msi_2_f, _ = MSIDP(msi_2_e_f)  # (B, 64, 512, 512) -> (B, 64, 512, 512)

                del hsi_1_e_f, msi_1_e_f, hsi_2_e_f, msi_2_e_f
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ6: è·¨æ¨¡æ€å¯¹é½æ„ŸçŸ¥ï¼ˆCross-Modality Alignment Perceptionï¼‰
                # æ ¸å¿ƒï¼šæ„é€ æœªé…å‡†å¯¹ï¼ˆPair1çš„HSI + Pair2çš„MSIï¼‰
                # ====================================================================
                # ğŸ”¥ å…³é”®è®¾è®¡ï¼šç”¨Pair1çš„HSIä½œä¸ºå‚è€ƒï¼ˆfixedï¼‰ï¼ŒPair2çš„MSIä½œä¸ºç§»åŠ¨ï¼ˆmovingï¼‰
                # è¿™æ ·å¯ä»¥å­¦ä¹ å¦‚ä½•å°†æœªé…å‡†çš„MSIå¯¹é½åˆ°HSI
                fixed_DP = HSIDP_hsi_1_f  # å‚è€ƒå›¾åƒç‰¹å¾ï¼ˆæ¥è‡ªPair1ï¼‰
                moving_DP = MSIDP_msi_2_f  # ç§»åŠ¨å›¾åƒç‰¹å¾ï¼ˆæ¥è‡ªPair2ï¼‰

                # çª—å£åˆ†å‰²
                moving_DP_lw = model.df_window_partition(
                    moving_DP,
                    args.args.large_w_size,  # 52
                    args.args.small_w_size  # 32
                )  # -> (num_windows, B, 64, 52, 52)

                fixed_DP_sw = model.window_partition(
                    fixed_DP,
                    args.args.small_w_size,  # 32
                    args.args.small_w_size  # 32
                )  # -> (num_windows, B, 64, 32, 32)

                # è®¡ç®—å¯¹é½æ„ŸçŸ¥çŸ©é˜µ
                correspondence_matrixs = model.CMAP(
                    fixed_DP_sw,  # å‚è€ƒçª—å£
                    moving_DP_lw,  # ç§»åŠ¨çª—å£
                    MHCSA_hsi,  # HSIçš„å¤šå¤´è·¨å°ºåº¦æ³¨æ„åŠ›
                    MHCSA_msi,  # MSIçš„å¤šå¤´è·¨å°ºåº¦æ³¨æ„åŠ›
                    True  # HSIä½œä¸ºå‚è€ƒ
                )  # -> (num_windows, B, 32*32, 52*52)

                del fixed_DP_sw, moving_DP_lw
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ7: ç‰¹å¾é‡ç»„å’Œæœ€ç»ˆèåˆ
                # æ ¹æ®å¯¹é½çŸ©é˜µé‡ç»„MSIç‰¹å¾ï¼Œä½¿å…¶ä¸HSIå¯¹é½
                # ====================================================================
                msi_2_f_sample = model.feature_reorganization(
                    correspondence_matrixs,  # å¯¹é½çŸ©é˜µ
                    msi_2_fe  # Pair2çš„MSIç‰¹å¾
                )  # -> (B, 64, 512, 512) - å¯¹é½åçš„MSIç‰¹å¾

                # æœ€ç»ˆèåˆï¼šPair1çš„HSI + å¯¹é½åçš„Pair2çš„MSI
                fusion_image_sample = fusion_module(
                    hsi_1_fe,  # Pair1çš„HSIç‰¹å¾
                    msi_2_f_sample  # å¯¹é½åçš„Pair2çš„MSIç‰¹å¾
                )  # -> (B, 31, 512, 512)

                # ====================================================================
                # é˜¶æ®µ8: æŸå¤±è®¡ç®—
                # ====================================================================

                # 8.1 åŸºç¡€èåˆæŸå¤±ï¼ˆç›‘ç£ä¸¤å¯¹é…å‡†æ•°æ®çš„èåˆè´¨é‡ï¼‰
                loss_fusion_1 = (
                        Lgrad(gt_1, gt_1, fusion_image_1) +
                        Loss.Loss_intensity(gt_1, gt_1, fusion_image_1) +
                        Lgrad(gt_1, gt_1, fusion_pimage_1) +
                        Loss.Loss_intensity(gt_1, gt_1, fusion_pimage_1)
                )

                loss_fusion_2 = (
                        Lgrad(gt_2, gt_2, fusion_image_2) +
                        Loss.Loss_intensity(gt_2, gt_2, fusion_image_2) +
                        Lgrad(gt_2, gt_2, fusion_pimage_2) +
                        Loss.Loss_intensity(gt_2, gt_2, fusion_pimage_2)
                )

                loss_0 = loss_fusion_1 + loss_fusion_2

                # 8.2 å­—å…¸ä¸€è‡´æ€§æŸå¤±ï¼ˆç¡®ä¿å­—å…¸è¡¥å¿åçš„ç‰¹å¾ä¸èåˆç‰¹å¾ä¸€è‡´ï¼‰
                loss_HSIDP = (
                        - CC(HSIDP_hsi_1_f, fusion_pf_1.detach())
                        - CC(HSIDP_hsi_2_f, fusion_pf_2.detach())
                )

                loss_MSIDP = (
                        - CC(MSIDP_msi_1_f, fusion_pf_1.detach())
                        - CC(MSIDP_msi_2_f, fusion_pf_2.detach())
                )

                # 8.3 æ¨¡æ€ä¸€è‡´æ€§æŸå¤±ï¼ˆç¡®ä¿HSIå’ŒMSIçš„å­—å…¸è¡¥å¿ç»“æœä¸€è‡´ï¼‰
                loss_same = (
                        F.mse_loss(HSIDP_hsi_1_f, MSIDP_msi_1_f) +
                        F.mse_loss(HSIDP_hsi_2_f, MSIDP_msi_2_f)
                )

                loss_1 = 2 * (loss_HSIDP + loss_MSIDP + 0.5 * loss_same)

                # 8.4 å¯¹é½èåˆæŸå¤±ï¼ˆç›‘ç£æœ€ç»ˆçš„å¯¹é½èåˆç»“æœï¼‰
                # æ³¨æ„ï¼šç”¨gt_1ç›‘ç£ï¼Œå› ä¸ºç”¨çš„æ˜¯hsi_1 + aligned(msi_2)
                loss_2 = (
                        Lgrad(gt_1, gt_1, fusion_image_sample) +
                        Loss.Loss_intensity(gt_1, gt_1, fusion_image_sample)
                )

                # 8.5 å¯¹é½ç›‘ç£æŸå¤±ï¼ˆæš‚æ—¶ç¦ç”¨ï¼Œéœ€è¦ä¿å­˜index_ræ‰èƒ½å¯ç”¨ï¼‰
                # å¦‚æœä½ åœ¨generate_deformed_gt.pyä¸­ä¿å­˜äº†å˜æ¢çŸ©é˜µï¼Œå¯ä»¥å¯ç”¨è¿™éƒ¨åˆ†
                # loss_correspondence_matrix, loss_correspondence_matrix_1 = Lcorrespondence(
                #     correspondence_matrixs, index_r
                # )
                # loss_3 = 4 * (loss_correspondence_matrix + loss_correspondence_matrix_1)

                # æ€»æŸå¤±
                loss = loss_0 + loss_1 + loss_2  # + loss_3 (éœ€è¦index_ræ—¶å¯ç”¨)

            # ========== åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰==========
            optimizer_HSIDP.zero_grad()
            optimizer_MSIDP.zero_grad()
            optimizer_MHCSAhsi.zero_grad()
            optimizer_MHCSAmsi.zero_grad()
            optimizer_FusionModule.zero_grad()
            optimizer_FE.zero_grad()

            scaler.scale(loss).backward()
            scaler.step(optimizer_FE)
            scaler.step(optimizer_HSIDP)
            scaler.step(optimizer_MSIDP)
            scaler.step(optimizer_MHCSAhsi)
            scaler.step(optimizer_MHCSAmsi)
            scaler.step(optimizer_FusionModule)
            scaler.update()

            # ========== æ˜¾å­˜æ¸…ç† ==========
            del hsi_1_f, msi_1_f, hsi_2_f, msi_2_f
            del hsi_1_fe, msi_1_fe, hsi_2_fe, msi_2_fe
            del HSIDP_hsi_1_f, MSIDP_msi_1_f, HSIDP_hsi_2_f, MSIDP_msi_2_f
            del fusion_f_1, fusion_pf_1, fusion_f_2, fusion_pf_2
            del correspondence_matrixs, msi_2_f_sample
            del fixed_DP, moving_DP
            torch.cuda.empty_cache()

            # ========== è®°å½•æŸå¤± ==========
            epoch_loss_HSIDP.append(loss_HSIDP.item())
            epoch_loss_MSIDP.append(loss_MSIDP.item())
            epoch_loss_same.append(loss_same.item())
            epoch_loss_fusion_total.append(loss.item())

            # ========== ä¿å­˜å›¾åƒï¼ˆå¯è§†åŒ–è®­ç»ƒè¿›åº¦ï¼‰==========
            if step % save_image_iter == 0:
                epoch_step_name = str(epoch) + "epoch" + str(step) + "step"
                if epoch % 2 == 0:
                    output_name = save_img_dir + "/" + epoch_step_name + ".jpg"

                    # ä¸Šé‡‡æ ·HSIç”¨äºå¯è§†åŒ–ï¼ˆå–å‰3é€šé“æ¨¡æ‹ŸRGBï¼‰
                    hsi_1_vis = F.interpolate(
                        hsi_1,
                        size=(msi_1.size(2), msi_1.size(3)),
                        mode='bilinear',
                        align_corners=False
                    )

                    # æ‹¼æ¥å›¾åƒï¼šHSI_1 | MSI_2 | Fusion_1 | Fusion_sample | Fusion_2
                    out = torch.cat([
                        hsi_1_vis[:, :3, :, :],  # Pair1çš„HSIï¼ˆRGBé€šé“ï¼‰
                        msi_2[:, :3, :, :],  # Pair2çš„MSI
                        fusion_image_1[:, :3, :, :],  # Pair1çš„èåˆç»“æœï¼ˆRGBé€šé“ï¼‰
                        fusion_image_sample[:, :3, :, :],  # å¯¹é½èåˆç»“æœï¼ˆRGBé€šé“ï¼‰
                        fusion_image_2[:, :3, :, :]  # Pair2çš„èåˆç»“æœï¼ˆRGBé€šé“ï¼‰
                    ], dim=3)

                    save_img(out, output_name)
                    del hsi_1_vis

            # ========== ä¿å­˜æ¨¡å‹ ==========
            if ((epoch + 1) == args.args.Epoch and (step + 1) % iter_num == 0) or \
                    (epoch % args.args.save_model_num == 0 and (step + 1) % iter_num == 0):
                ckpts = {
                    "bfe_msi": base_msi.state_dict(),
                    "bfe_hsi": base_hsi.state_dict(),
                    "msi_mfe": msi_MFE.state_dict(),
                    "hsi_mfe": hsi_MFE.state_dict(),
                    "pafe": PAFE.state_dict(),
                    "fusion_decoder": fusion_decoder.state_dict(),
                    "decoder": decoder.state_dict(),
                    "mn_msi": MN_msi.state_dict(),
                    "mn_hsi": MN_hsi.state_dict(),
                    "msi_dgfp": MSIDP.state_dict(),
                    "hsi_dgfp": HSIDP.state_dict(),
                    "mhcsab_msi": MHCSA_msi.state_dict(),
                    "mhcsab_hsi": MHCSA_hsi.state_dict(),
                    "fusion_block": fusion_module.state_dict(),
                }
                save_dir = '{:s}/epoch{:d}_iter{:d}.pth'.format(save_model_dir, epoch, step + 1)
                torch.save(ckpts, save_dir)
                print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_dir}")

            # ========== æœ€ç»ˆæ¸…ç† ==========
            del hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2
            del fusion_image_1, fusion_pimage_1, fusion_image_2, fusion_pimage_2, fusion_image_sample
            torch.cuda.empty_cache()

        # ========== æ‰“å°epochç»Ÿè®¡ä¿¡æ¯ ==========
        epoch_loss_HSIDP_mean = np.mean(epoch_loss_HSIDP)
        epoch_loss_MSIDP_mean = np.mean(epoch_loss_MSIDP)
        epoch_loss_same_mean = np.mean(epoch_loss_same)
        epoch_loss_fusion_mean = np.mean(epoch_loss_fusion_total)

        print()
        print(f"ğŸ“Š Epoch {epoch} ç»Ÿè®¡:")
        print(f"   - æ€»æŸå¤±(Total Loss):     {epoch_loss_fusion_mean:.6f}")
        print(f"   - HSIå­—å…¸æŸå¤±(HSIDP):      {epoch_loss_HSIDP_mean:.6f}")
        print(f"   - MSIå­—å…¸æŸå¤±(MSIDP):      {epoch_loss_MSIDP_mean:.6f}")
        print(f"   - æ¨¡æ€ä¸€è‡´æ€§æŸå¤±(Same):    {epoch_loss_same_mean:.6f}")



    """
        è¾“å…¥: 6ä¸ªå¼ é‡
â”œâ”€â”€ Pair 1: hsi_1, msi_1, gt_1  (æ¥è‡ª Z_reconst, Y_reconst, X)
â””â”€â”€ Pair 2: hsi_2, msi_2, gt_2  (æ¥è‡ª Z_deformed, Y_deformed, X_deformed)

æ ¸å¿ƒè®¾è®¡:
â”œâ”€â”€ ç”¨Pair1å’ŒPair2åˆ†åˆ«è®­ç»ƒåŸºç¡€èåˆèƒ½åŠ›
â””â”€â”€ æ„é€ æœªé…å‡†å¯¹: hsi_1 + msi_2 (è·¨Pairæ„é€ )
    â””â”€â”€ é€šè¿‡CMAPå­¦ä¹ å¯¹é½å…³ç³»
        â””â”€â”€ ç”Ÿæˆæœ€ç»ˆå¯¹é½èåˆç»“æœ
        """



    # ========== å¯åŠ¨è®­ç»ƒå¾ªç¯ ==========
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“Œ è®­ç»ƒå‚æ•°:")
    print(f"   - Epochs: {args.args.Epoch}")
    print(f"   - Batch Size: {args.args.batch_size}")
    print(f"   - è®­ç»ƒæ ·æœ¬æ•°: {len(dataset)}")
    print(f"   - æ¯epochè¿­ä»£æ•°: {iter_num}")
    print(f"   - å›¾åƒå°ºå¯¸: {args.args.img_size}Ã—{args.args.img_size}")
    print(f"   - æ··åˆç²¾åº¦: å·²å¯ç”¨\n")

    for epoch in tqdm(range(args.args.Epoch), desc="è®­ç»ƒè¿›åº¦"):
        if epoch < args.args.Warm_epoch:
            warmup_learning_rate(optimizer_MHCSAhsi, epoch)
            warmup_learning_rate(optimizer_MHCSAmsi, epoch)
        else:
            adjust_learning_rate(optimizer_MHCSAhsi, epoch)
            adjust_learning_rate(optimizer_MHCSAmsi, epoch)

        train(epoch)

    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")