import os
import time
from pathlib import Path

import math
import numpy as np
import torch
import torch.nn.functional as F
import torch.utils.data as data
import torchvision
import scipy.io as sio
from PIL import Image
from torch.cuda.amp import autocast, GradScaler

from utils.utils import save_img
from tqdm import tqdm

import args
from loss import loss as Loss
from model import model
from utils import utils

# å…¨å±€å¸¸é‡å®šä¹‰
model_name = "MulFS-CAP-HSI-MSI"
device_id = "0"


def adjust_learning_rate(optimizer, epoch_count):
    lr = args.args.LR + 0.5 * (args.args.LR_target - args.args.LR) * (
            1 + math.cos((epoch_count - args.args.Warm_epoch) / (args.args.Epoch - args.args.Warm_epoch) * math.pi))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


def warmup_learning_rate(optimizer, epoch_count):
    lr = epoch_count * ((args.args.LR_target - args.args.LR) / args.args.Warm_epoch) + args.args.LR
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


class TrainDataset(data.Dataset):
    def __init__(self, hsi_dir, msi_dir, gt_dir, transform=None):
        super(TrainDataset, self).__init__()
        self.hsi_dir = hsi_dir
        self.msi_dir = msi_dir
        self.gt_dir = gt_dir
        self.hsi_paths = self.find_mat_files(self.hsi_dir)
        self.msi_paths = self.find_mat_files(self.msi_dir)
        self.gt_paths = self.find_mat_files(self.gt_dir)

        assert len(self.hsi_paths) == len(self.msi_paths) == len(self.gt_paths), \
            f"HSIã€MSIå’ŒGTæ–‡ä»¶æ•°é‡ä¸ç›¸ç­‰: {len(self.hsi_paths)}, {len(self.msi_paths)}, {len(self.gt_paths)}"

        self.transform = transform
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(self.hsi_paths)} å¯¹æ ·æœ¬")

    def find_mat_files(self, dir_path):
        """æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶"""
        mat_files = []
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                if file.endswith('.mat'):
                    mat_files.append(os.path.join(root, file))
        mat_files.sort()  # ç¡®ä¿é¡ºåºä¸€è‡´
        return mat_files

    def read_mat_image(self, path, key=None):
        """
        è¯»å–.matæ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ®

        å‚æ•°:
            path: .matæ–‡ä»¶è·¯å¾„
            key: .matæ–‡ä»¶ä¸­çš„å˜é‡åï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨æŸ¥æ‰¾ï¼‰

        è¿”å›:
            torch.Tensor: shapeä¸º(C, H, W)çš„å¼ é‡
        """
        try:
            mat_data = sio.loadmat(path)

            # è‡ªåŠ¨æŸ¥æ‰¾æ•°æ®é”®ï¼ˆæ’é™¤MATLABå…ƒæ•°æ®ï¼‰
            if key is None:
                valid_keys = [k for k in mat_data.keys() if not k.startswith('__')]
                if len(valid_keys) == 0:
                    raise ValueError(f"æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®é”®: {path}")
                key = valid_keys[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆé”®

            img = mat_data[key]  # shape: (H, W, C)

            # è½¬æ¢ä¸ºtorchå¼ é‡å¹¶è°ƒæ•´ç»´åº¦é¡ºåº: (H, W, C) -> (C, H, W)
            img = torch.from_numpy(img).float()
            if img.ndim == 2:  # å¦‚æœæ˜¯2Dï¼Œæ·»åŠ é€šé“ç»´åº¦
                img = img.unsqueeze(0)
            elif img.ndim == 3:
                img = img.permute(2, 0, 1)  # (H, W, C) -> (C, H, W)

            # å½’ä¸€åŒ–åˆ°[0, 1]ï¼ˆå¦‚æœæ•°æ®èŒƒå›´ä¸æ˜¯[0,1]ï¼‰
            if img.max() > 1.0:
                img = img / img.max()

            # åº”ç”¨transformï¼ˆå¦‚æœéœ€è¦resizeï¼‰
            if self.transform is not None:
                img = self.transform(img)

            return img

        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {path}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            raise

    def __getitem__(self, index):
        hsi_path = self.hsi_paths[index]
        msi_path = self.msi_paths[index]
        gt_path = self.gt_paths[index]

        # è¯»å–æ•°æ®
        # HSI: (31, 16, 16) - 31é€šé“ï¼Œä½åˆ†è¾¨ç‡
        # MSI: (3, 512, 512) - 3é€šé“ï¼Œé«˜åˆ†è¾¨ç‡
        # GT:  (31, 512, 512) - 31é€šé“ï¼Œé«˜åˆ†è¾¨ç‡
        hsi_img = self.read_mat_image(hsi_path)  # (31, 16, 16)
        msi_img = self.read_mat_image(msi_path)  # (3, 512, 512)
        gt_img = self.read_mat_image(gt_path)  # (31, 512, 512)

        return hsi_img, msi_img, gt_img

    def __len__(self):
        return len(self.hsi_paths)


# æ ¸å¿ƒï¼šæ‰€æœ‰æ‰§è¡Œé€»è¾‘å¿…é¡»åŒ…è£¹åˆ°if __name__ == '__main__'ä¸­
if __name__ == '__main__':
    # ========== åˆå§‹åŒ–ç¯å¢ƒ ==========
    os.environ['CUDA_LAUNCH_BLOCKING'] = device_id
    device = torch.device("cuda:" + device_id if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        torch.multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        pass

    # ========== åˆå§‹åŒ–ä¿å­˜ç›®å½• ==========
    now = int(time.time())
    timeArr = time.localtime(now)
    nowTime = time.strftime("%Y%m%d_%H-%M-%S", timeArr)
    save_model_dir = args.args.train_save_model_dir + "/" + nowTime + "_" + model_name + "_model"
    save_img_dir = args.args.train_save_img_dir + "/" + nowTime + "_" + model_name + "_img"
    utils.check_dir(save_model_dir)
    utils.check_dir(save_img_dir)

    # ========== æ•°æ®åŠ è½½å™¨åˆå§‹åŒ– ==========
    tf = None

    dataset = TrainDataset(args.args.hsi_train_dir, args.args.msi_train_dir, args.args.gt_train_dir, tf)

    data_iter = data.DataLoader(
        dataset=dataset,
        shuffle=True,
        batch_size=args.args.batch_size,
        num_workers=4,
        pin_memory=True,
        drop_last=True,
        multiprocessing_context=torch.multiprocessing.get_context('spawn')
    )

    iter_num = int(dataset.__len__() / args.args.batch_size)
    save_image_iter = max(1, int(iter_num / args.args.save_image_num))

    # ========== æ¨¡å‹åˆå§‹åŒ– ==========
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    Lgrad = Loss.L_Grad().to(device)
    CC = Loss.CorrelationCoefficient().to(device)
    Lcorrespondence = Loss.L_correspondence()

    # âœ… å…³é”®ä¿®å¤1: åˆ›å»ºä¸¤ä¸ªä¸åŒçš„baseæ¨¡å—
    with torch.no_grad():
        base_msi = model.base(in_channels=3)  # MSI: 3é€šé“ -> 64é€šé“
        base_hsi = model.base(in_channels=31)  # HSI: 31é€šé“ -> 64é€šé“
        hsi_MFE = model.FeatureExtractor()
        msi_MFE = model.FeatureExtractor()
        fusion_decoder = model.Decoder()
        PAFE = model.FeatureExtractor()
        decoder = model.Decoder()
        MN_hsi = model.Enhance()
        MN_msi = model.Enhance()
        HSIDP = model.DictionaryRepresentationModule()
        MSIDP = model.DictionaryRepresentationModule()
        ImageDeformation = model.ImageTransform()
        MHCSA_hsi = model.MHCSAB()
        MHCSA_msi = model.MHCSAB()
        fusion_module = model.FusionMoudle()

    # æ¨¡å‹è®­ç»ƒæ¨¡å¼+è®¾å¤‡è¿ç§»
    print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°GPU...")
    base_msi.train().to(device)
    base_hsi.train().to(device)
    hsi_MFE.train().to(device)
    msi_MFE.train().to(device)
    fusion_decoder.train().to(device)
    PAFE.train().to(device)
    decoder.train().to(device)
    HSIDP.train().to(device)
    MSIDP.train().to(device)
    MN_hsi.train().to(device)
    MN_msi.train().to(device)
    MHCSA_hsi.train().to(device)
    MHCSA_msi.train().to(device)
    fusion_module.train().to(device)

    # ========== ä¼˜åŒ–å™¨åˆå§‹åŒ– ==========
    print("âš™ï¸ æ­£åœ¨é…ç½®ä¼˜åŒ–å™¨...")
    optimizer_FE = torch.optim.Adam([
        {'params': base_msi.parameters()},  # âœ… ä¿®å¤2: åŒ…å«ä¸¤ä¸ªbase
        {'params': base_hsi.parameters()},
        {'params': hsi_MFE.parameters()},
        {'params': msi_MFE.parameters()},
        {'params': fusion_decoder.parameters()},
        {'params': PAFE.parameters()},
        {'params': decoder.parameters()},
        {'params': MN_hsi.parameters()},
        {'params': MN_msi.parameters()}
    ], lr=0.0002)

    optimizer_HSIDP = torch.optim.Adam(HSIDP.parameters(), lr=0.0008)
    optimizer_MSIDP = torch.optim.Adam(MSIDP.parameters(), lr=0.0008)
    optimizer_MHCSAhsi = torch.optim.Adam(MHCSA_hsi.parameters(), lr=args.args.LR)
    optimizer_MHCSAmsi = torch.optim.Adam(MHCSA_msi.parameters(), lr=args.args.LR)
    optimizer_FusionModule = torch.optim.Adam(fusion_module.parameters(), lr=0.0002)

    # âœ… ä¼˜åŒ–3: æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()
    print("âœ… å·²å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ï¼Œæ˜¾å­˜å ç”¨å°†å‡å°‘çº¦50%")


    # ========== è®­ç»ƒå‡½æ•°å®šä¹‰ ==========
    def train(epoch):
        epoch_loss_HSIDP = []
        epoch_loss_MSIDP = []
        epoch_loss_same = []
        epoch_loss_correspondence_matrix = []
        epoch_loss_correspondence_predict = []

        for step, x in enumerate(data_iter):
            # æ•°æ®åŠ è½½
            hsi = x[0].to(device, non_blocking=True)
            msi = x[1].to(device, non_blocking=True)
            gt = x[2].to(device, non_blocking=True)

            # ========== âœ… å…³é”®ä¿®å¤ï¼šImageDeformationåœ¨autocastå¤–æ‰§è¡Œ ==========
            # å…ˆä¸Šé‡‡æ ·HSIï¼ˆåœ¨autocastå¤–ï¼Œä½¿ç”¨FP32ï¼‰
            hsi_upsampled = F.interpolate(
                hsi,
                size=(msi.size(2), msi.size(3)),
                mode='bilinear',
                align_corners=False
            )

            # âœ… ImageDeformationä¸ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆé¿å…torch.inverseé”™è¯¯ï¼‰
            with torch.no_grad():
                hsi_d, msi_d, _, index_r, _ = ImageDeformation(hsi_upsampled, msi)

            # ========== å…¶ä»–éƒ¨åˆ†ä½¿ç”¨æ··åˆç²¾åº¦ ==========
            with autocast():
                # ========== é˜¶æ®µ2: åŸºç¡€ç‰¹å¾æå– ==========
                hsi_1 = base_hsi(hsi_upsampled)
                hsi_d_1 = base_hsi(hsi_d)
                msi_1 = base_msi(msi)
                msi_d_1 = base_msi(msi_d)

                # âœ… é‡Šæ”¾ä¸å†éœ€è¦çš„å¼ é‡
                del hsi_upsampled
                torch.cuda.empty_cache()

                # ========== é˜¶æ®µ3: æ·±å±‚ç‰¹å¾æå–ï¼ˆç¬¬ä¸€è·¯å¾„ï¼‰ ==========
                hsi_fe = hsi_MFE(hsi_1)
                msi_fe = msi_MFE(msi_1)
                simple_fusion_f_1 = hsi_fe + msi_fe
                fusion_image_1, fusion_f_1 = fusion_decoder(simple_fusion_f_1)

                del simple_fusion_f_1
                torch.cuda.empty_cache()

                hsi_d_fe = hsi_MFE(hsi_d_1)
                msi_d_fe = msi_MFE(msi_d_1)
                simple_fusion_d_f_1 = hsi_d_fe + msi_d_fe
                fusion_d_image_1, fusion_d_f_1 = fusion_decoder(simple_fusion_d_f_1)

                del simple_fusion_d_f_1
                torch.cuda.empty_cache()

                # ========== é˜¶æ®µ4: PAFEç‰¹å¾æå– ==========
                hsi_f = PAFE(hsi_1)
                msi_f = PAFE(msi_1)
                simple_fusion_f = hsi_f + msi_f
                fusion_image, fusion_f = decoder(simple_fusion_f)

                del simple_fusion_f, hsi_1
                torch.cuda.empty_cache()

                hsi_d_f = PAFE(hsi_d_1)
                msi_d_f = PAFE(msi_d_1)
                simple_fusion_d_f = hsi_d_f + msi_d_f
                fusion_d_image, fusion_d_f = decoder(simple_fusion_d_f)

                del simple_fusion_d_f, hsi_d_1, msi_1, msi_d_1
                torch.cuda.empty_cache()

                # ========== é˜¶æ®µ5: æ¨¡æ€å½’ä¸€åŒ–å’Œå­—å…¸è¡¥å¿ ==========
                hsi_e_f = MN_hsi(hsi_f)
                msi_e_f = MN_msi(msi_f)
                hsi_d_e_f = MN_hsi(hsi_d_f)
                msi_d_e_f = MN_msi(msi_d_f)

                HSIDP_hsi_f, _ = HSIDP(hsi_e_f)
                MSIDP_msi_f, _ = MSIDP(msi_e_f)
                HSIDP_hsi_d_f, _ = HSIDP(hsi_d_e_f)
                MSIDP_msi_d_f, _ = MSIDP(msi_d_e_f)

                del hsi_e_f, msi_e_f, hsi_d_e_f, msi_d_e_f
                torch.cuda.empty_cache()

                # ========== é˜¶æ®µ6: è·¨æ¨¡æ€å¯¹é½æ„ŸçŸ¥ ==========
                fixed_DP = HSIDP_hsi_f
                moving_DP = MSIDP_msi_d_f

                moving_DP_lw = model.df_window_partition(moving_DP, args.args.large_w_size, args.args.small_w_size)
                fixed_DP_sw = model.window_partition(fixed_DP, args.args.small_w_size, args.args.small_w_size)

                correspondence_matrixs = model.CMAP(fixed_DP_sw, moving_DP_lw, MHCSA_hsi, MHCSA_msi, True)

                del fixed_DP_sw, moving_DP_lw
                torch.cuda.empty_cache()

                # ========== é˜¶æ®µ7: ç‰¹å¾é‡ç»„å’Œæœ€ç»ˆèåˆ ==========
                msi_d_f_sample = model.feature_reorganization(correspondence_matrixs, msi_d_fe)
                fusion_image_sample = fusion_module(hsi_fe, msi_d_f_sample)

                # ========== é˜¶æ®µ8: æŸå¤±è®¡ç®— ==========
                loss_fusion = Lgrad(gt, gt, fusion_image) + Loss.Loss_intensity(gt, gt, fusion_image) + \
                              Lgrad(gt, gt, fusion_d_image) + Loss.Loss_intensity(gt, gt, fusion_d_image)

                loss_fusion_1 = Lgrad(gt, gt, fusion_image_1) + Loss.Loss_intensity(gt, gt, fusion_image_1) + \
                                Lgrad(gt, gt, fusion_d_image_1) + Loss.Loss_intensity(gt, gt, fusion_d_image_1)

                loss_0 = loss_fusion

                loss_HSIDP = - CC(HSIDP_hsi_f, fusion_f.detach()) - CC(HSIDP_hsi_d_f, fusion_d_f.detach())
                loss_MSIDP = - CC(MSIDP_msi_f, fusion_f.detach()) - CC(MSIDP_msi_d_f, fusion_d_f.detach())
                loss_same = F.mse_loss(HSIDP_hsi_f, MSIDP_msi_f) + F.mse_loss(HSIDP_hsi_d_f, MSIDP_msi_d_f)

                loss_1 = 2 * (loss_HSIDP + loss_MSIDP + loss_same)
                loss_2 = Lgrad(gt, gt, fusion_image_sample) + Loss.Loss_intensity(gt, gt, fusion_image_sample)

                loss_correspondence_matrix, loss_correspondence_matrix_1 = Lcorrespondence(
                    correspondence_matrixs, index_r)
                loss_3 = 4 * (loss_correspondence_matrix + loss_correspondence_matrix_1)

                loss = loss_0 + loss_1 + loss_2 + loss_3 + loss_fusion_1

            # ========== åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰ ==========
            optimizer_HSIDP.zero_grad()
            optimizer_MSIDP.zero_grad()
            optimizer_MHCSAhsi.zero_grad()
            optimizer_MHCSAmsi.zero_grad()
            optimizer_FusionModule.zero_grad()
            optimizer_FE.zero_grad()

            scaler.scale(loss).backward()
            scaler.step(optimizer_FE)
            scaler.step(optimizer_HSIDP)
            scaler.step(optimizer_MSIDP)
            scaler.step(optimizer_MHCSAhsi)
            scaler.step(optimizer_MHCSAmsi)
            scaler.step(optimizer_FusionModule)
            scaler.update()

            # âœ… æ˜¾å­˜æ¸…ç†
            del hsi_f, msi_f, hsi_d_f, msi_d_f
            del hsi_fe, msi_fe, hsi_d_fe, msi_d_fe
            del HSIDP_hsi_f, MSIDP_msi_f, HSIDP_hsi_d_f, MSIDP_msi_d_f
            del fusion_f, fusion_d_f, fusion_f_1, fusion_d_f_1
            del correspondence_matrixs, msi_d_f_sample
            del fixed_DP, moving_DP
            torch.cuda.empty_cache()

            # è®°å½•æŸå¤±
            epoch_loss_HSIDP.append(loss_HSIDP.item())
            epoch_loss_MSIDP.append(loss_MSIDP.item())
            epoch_loss_same.append(loss_same.item())
            epoch_loss_correspondence_matrix.append(loss_correspondence_matrix.item())
            epoch_loss_correspondence_predict.append(loss_correspondence_matrix_1.item())

            # ä¿å­˜å›¾åƒ
            if step % save_image_iter == 0:
                epoch_step_name = str(epoch) + "epoch" + str(step) + "step"
                if epoch % 2 == 0:
                    output_name = save_img_dir + "/" + epoch_step_name + ".jpg"
                    # ä¸Šé‡‡æ ·HSIç”¨äºå¯è§†åŒ–
                    hsi_vis = F.interpolate(hsi, size=(msi.size(2), msi.size(3)), mode='bilinear', align_corners=False)
                    out = torch.cat([
                        hsi_vis[:, :3, :, :],
                        msi_d[:, :3, :, :],
                        fusion_image_1[:, :3, :, :],
                        fusion_image_sample[:, :3, :, :],
                        fusion_d_image_1[:, :3, :, :]
                    ], dim=3)
                    save_img(out, output_name)
                    del hsi_vis

            # ä¿å­˜æ¨¡å‹
            if ((epoch + 1) == args.args.Epoch and (step + 1) % iter_num == 0) or \
                    (epoch % args.args.save_model_num == 0 and (step + 1) % iter_num == 0):
                ckpts = {
                    "bfe_msi": base_msi.state_dict(),
                    "bfe_hsi": base_hsi.state_dict(),
                    "msi_mfe": msi_MFE.state_dict(),
                    "hsi_mfe": hsi_MFE.state_dict(),
                    "pafe": PAFE.state_dict(),
                    "fusion_decoder": fusion_decoder.state_dict(),
                    "decoder": decoder.state_dict(),
                    "mn_msi": MN_msi.state_dict(),
                    "mn_hsi": MN_hsi.state_dict(),
                    "msi_dgfp": MSIDP.state_dict(),
                    "hsi_dgfp": HSIDP.state_dict(),
                    "mhcsab_msi": MHCSA_msi.state_dict(),
                    "mhcsab_hsi": MHCSA_hsi.state_dict(),
                    "fusion_block": fusion_module.state_dict(),
                }
                save_dir = '{:s}/epoch{:d}_iter{:d}.pth'.format(save_model_dir, epoch, step + 1)
                torch.save(ckpts, save_dir)
                print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_dir}")

            # âœ… æœ€ç»ˆæ¸…ç†
            del hsi, msi, gt, hsi_d, msi_d
            del fusion_image, fusion_d_image, fusion_image_1, fusion_d_image_1, fusion_image_sample
            torch.cuda.empty_cache()

        # æ‰“å°epochæŸå¤±
        epoch_loss_correspondence_matrix_mean = np.mean(epoch_loss_correspondence_matrix)
        epoch_loss_correspondence_predict_mean = np.mean(epoch_loss_correspondence_predict)
        epoch_loss_HSIDP_mean = np.mean(epoch_loss_HSIDP)
        epoch_loss_MSIDP_mean = np.mean(epoch_loss_MSIDP)
        epoch_loss_same_mean = np.mean(epoch_loss_same)

        print()
        print(f"ğŸ“Š -epoch {epoch}")
        print(
            f"   -loss_cm {epoch_loss_correspondence_matrix_mean:.6f} -loss_cp {epoch_loss_correspondence_predict_mean:.6f}")
        print(f"   -loss_HSIDP {epoch_loss_HSIDP_mean:.6f} -loss_MSIDP {epoch_loss_MSIDP_mean:.6f}")
        print(f"   -loss_same {epoch_loss_same_mean:.6f}")


    # ========== å¯åŠ¨è®­ç»ƒå¾ªç¯ ==========
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“Œ è®­ç»ƒå‚æ•°:")
    print(f"   - Epochs: {args.args.Epoch}")
    print(f"   - Batch Size: {args.args.batch_size}")
    print(f"   - è®­ç»ƒæ ·æœ¬æ•°: {len(dataset)}")
    print(f"   - æ¯epochè¿­ä»£æ•°: {iter_num}")
    print(f"   - å›¾åƒå°ºå¯¸: {args.args.img_size}Ã—{args.args.img_size}")
    print(f"   - æ··åˆç²¾åº¦: å·²å¯ç”¨\n")

    for epoch in tqdm(range(args.args.Epoch), desc="è®­ç»ƒè¿›åº¦"):
        if epoch < args.args.Warm_epoch:
            warmup_learning_rate(optimizer_MHCSAhsi, epoch)
            warmup_learning_rate(optimizer_MHCSAmsi, epoch)
        else:
            adjust_learning_rate(optimizer_MHCSAhsi, epoch)
            adjust_learning_rate(optimizer_MHCSAmsi, epoch)

        train(epoch)

    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")