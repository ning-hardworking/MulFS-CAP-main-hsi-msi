import os
import time
from pathlib import Path

import math
import numpy as np
import torch
import torch.nn.functional as F
import torch.utils.data as data
import scipy.io as sio
from torch.cuda.amp import autocast, GradScaler
from tqdm import tqdm

import args
from loss import loss as Loss
from model import model
from utils import utils

# å…¨å±€å¸¸é‡å®šä¹‰
model_name = "MulFS-CAP-HSI-MSI"
device_id = "0"


def adjust_learning_rate(optimizer, epoch_count):
    lr = args.args.LR + 0.5 * (args.args.LR_target - args.args.LR) * (
            1 + math.cos((epoch_count - args.args.Warm_epoch) / (args.args.Epoch - args.args.Warm_epoch) * math.pi))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


def warmup_learning_rate(optimizer, epoch_count):
    lr = epoch_count * ((args.args.LR_target - args.args.LR) / args.args.Warm_epoch) + args.args.LR
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    return lr


class TrainDataset(data.Dataset):
    def __init__(self, hsi_dir, msi_dir, gt_dir,
                 hsi_deformed_dir, msi_deformed_dir, gt_deformed_dir,
                 transform=None, target_size=512):  # âœ… é»˜è®¤512
        super(TrainDataset, self).__init__()

        self.target_size = target_size

        # Pair 1: åŸå§‹é…å‡†æ•°æ®
        self.hsi_paths = self.find_mat_files(hsi_dir)
        self.msi_paths = self.find_mat_files(msi_dir)
        self.gt_paths = self.find_mat_files(gt_dir)

        # Pair 2: å½¢å˜é…å‡†æ•°æ®
        self.hsi_d_paths = self.find_mat_files(hsi_deformed_dir)
        self.msi_d_paths = self.find_mat_files(msi_deformed_dir)
        self.gt_d_paths = self.find_mat_files(gt_deformed_dir)

        assert len(self.hsi_paths) == len(self.hsi_d_paths), \
            f"é…å¯¹æ•°æ®æ•°é‡ä¸ä¸€è‡´: Pair1={len(self.hsi_paths)}, Pair2={len(self.hsi_d_paths)}"

        self.transform = transform
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ (ç›®æ ‡å°ºå¯¸: {target_size}Ã—{target_size}):")
        print(f"   - Pair 1 (åŸå§‹é…å‡†): {len(self.hsi_paths)} å¯¹æ ·æœ¬")
        print(f"   - Pair 2 (å½¢å˜é…å‡†): {len(self.hsi_d_paths)} å¯¹æ ·æœ¬")

        # âœ… æ–°å¢ï¼šæ˜¾ç¤ºå…³é”®å‚æ•°
        print(f"\nğŸ“ å°ºå¯¸å‚æ•°:")
        print(f"   - MSI/GTç›®æ ‡å°ºå¯¸: {target_size}Ã—{target_size}")
        print(f"   - HSIç›®æ ‡å°ºå¯¸: {target_size // 32}Ã—{target_size // 32}")
        print(f"   - ä¸‹é‡‡æ ·æ¯”ä¾‹: 32")

    def find_mat_files(self, dir_path):
        """æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶"""
        mat_files = []
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                if file.endswith('.mat'):
                    mat_files.append(os.path.join(root, file))
        mat_files.sort()
        return mat_files

    def read_mat_image(self, path, key=None):
        """è¯»å–.matæ–‡ä»¶ï¼ˆå·²ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            mat_data = sio.loadmat(path)

            if key is None:
                valid_keys = [k for k in mat_data.keys() if not k.startswith('__')]
                if len(valid_keys) == 0:
                    raise ValueError(f"æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®é”®: {path}")
                key = valid_keys[0]

            img = mat_data[key]

            # æ™ºèƒ½è¯†åˆ«é€šé“ç»´åº¦
            if img.ndim == 2:
                img = torch.from_numpy(img).float().unsqueeze(0)
            elif img.ndim == 3:
                shape = img.shape
                expected_channels = [3, 31]
                channel_dim_idx = None

                for i, s in enumerate(shape):
                    if s in expected_channels:
                        channel_dim_idx = i
                        break

                if channel_dim_idx is not None:
                    target_dim = channel_dim_idx
                else:
                    target_dim = np.argmin(shape)

                img = np.moveaxis(img, source=target_dim, destination=0)
                img = torch.from_numpy(img).float()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒç»´åº¦: {img.ndim}Dï¼Œè·¯å¾„: {path}")

            # å½’ä¸€åŒ–
            if img.max() > 1.0:
                img = img / img.max()

            if self.transform is not None:
                img = self.transform(img)

            return img

        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {path}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            raise

    def __getitem__(self, index):
        # Pair 1: åŸå§‹é…å‡†å¯¹
        hsi_1 = self.read_mat_image(self.hsi_paths[index])
        msi_1 = self.read_mat_image(self.msi_paths[index])
        gt_1 = self.read_mat_image(self.gt_paths[index])

        # Pair 2: å½¢å˜é…å‡†å¯¹
        hsi_2 = self.read_mat_image(self.hsi_d_paths[index])
        msi_2 = self.read_mat_image(self.msi_d_paths[index])
        gt_2 = self.read_mat_image(self.gt_d_paths[index])

        # ========== ğŸ”¥ Resizeåˆ°ç›®æ ‡å°ºå¯¸ ğŸ”¥ ==========
        # âœ… ä¿®æ­£ï¼šä¿æŒå›ºå®šçš„ä¸‹é‡‡æ ·æ¯”ä¾‹ 32
        original_ratio = 32  # åŸå§‹æ•°æ®: 512/16 = 32
        hsi_target_size = self.target_size // original_ratio  # 512 // 32 = 16

        # âœ… éªŒè¯å°ºå¯¸åˆç†æ€§
        if hsi_target_size < 8:
            raise ValueError(
                f"âŒ HSIç›®æ ‡å°ºå¯¸({hsi_target_size}Ã—{hsi_target_size})å¤ªå°ï¼"
                f"å»ºè®® img_size >= 256"
            )

        # Resize MSIå’ŒGTï¼ˆä¿æŒåŸå§‹512Ã—512ï¼Œæˆ–resizeåˆ°target_sizeï¼‰
        if msi_1.size(-1) != self.target_size:
            msi_1 = F.interpolate(msi_1.unsqueeze(0), size=(self.target_size, self.target_size),
                                  mode='bilinear', align_corners=False).squeeze(0)
            gt_1 = F.interpolate(gt_1.unsqueeze(0), size=(self.target_size, self.target_size),
                                 mode='bilinear', align_corners=False).squeeze(0)

            msi_2 = F.interpolate(msi_2.unsqueeze(0), size=(self.target_size, self.target_size),
                                  mode='bilinear', align_corners=False).squeeze(0)
            gt_2 = F.interpolate(gt_2.unsqueeze(0), size=(self.target_size, self.target_size),
                                 mode='bilinear', align_corners=False).squeeze(0)

        # Resize HSIï¼ˆä¿æŒåŸå§‹16Ã—16ï¼Œæˆ–resizeåˆ°hsi_target_sizeï¼‰
        if hsi_1.size(-1) != hsi_target_size:
            hsi_1 = F.interpolate(hsi_1.unsqueeze(0), size=(hsi_target_size, hsi_target_size),
                                  mode='bilinear', align_corners=False).squeeze(0)
            hsi_2 = F.interpolate(hsi_2.unsqueeze(0), size=(hsi_target_size, hsi_target_size),
                                  mode='bilinear', align_corners=False).squeeze(0)

        return hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2

    def __len__(self):
        return len(self.hsi_paths)


# æ ¸å¿ƒï¼šæ‰€æœ‰æ‰§è¡Œé€»è¾‘å¿…é¡»åŒ…è£¹åˆ°if __name__ == '__main__'ä¸­
if __name__ == '__main__':
    # ========== åˆå§‹åŒ–ç¯å¢ƒ ==========
    os.environ['CUDA_LAUNCH_BLOCKING'] = device_id
    device = torch.device("cuda:" + device_id if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        torch.multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        pass

    # ========== åˆå§‹åŒ–ä¿å­˜ç›®å½• ==========
    now = int(time.time())
    timeArr = time.localtime(now)
    nowTime = time.strftime("%Y%m%d_%H-%M-%S", timeArr)
    save_model_dir = args.args.train_save_model_dir + "/" + nowTime + "_" + model_name + "_model"
    save_img_dir = args.args.train_save_img_dir + "/" + nowTime + "_" + model_name + "_img"
    utils.check_dir(save_model_dir)
    utils.check_dir(save_img_dir)

    # ========== æ•°æ®åŠ è½½å™¨åˆå§‹åŒ– ==========

    # âœ… ä¿®æ”¹æ•°æ®é›†åˆå§‹åŒ–
    tf = None

    dataset = TrainDataset(
        args.args.hsi_train_dir,
        args.args.msi_train_dir,
        args.args.gt_train_dir,
        args.args.hsi_deformed_train_dir,
        args.args.msi_deformed_train_dir,
        args.args.gt_deformed_train_dir,
        tf,
        target_size=args.args.img_size  # âœ… ä¼ å…¥ç›®æ ‡å°ºå¯¸
    )

    data_iter = data.DataLoader(
        dataset=dataset,
        shuffle=True,
        batch_size=args.args.batch_size,
        num_workers=4,
        pin_memory=True,
        drop_last=True,
        multiprocessing_context=torch.multiprocessing.get_context('spawn')
    )

    iter_num = int(dataset.__len__() / args.args.batch_size)
    save_image_iter = max(1, int(iter_num / args.args.save_image_num))

    # ========== æŸå¤±å‡½æ•°åˆå§‹åŒ– ==========
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æŸå¤±å‡½æ•°...")
    Lgrad = Loss.L_Grad().to(device)
    CC = Loss.CorrelationCoefficient().to(device)
    Lcorrespondence = Loss.L_correspondence()

    # âœ… æ–°å¢ï¼š31é€šé“ä¸“ç”¨æŸå¤±å‡½æ•°
    SpectralLoss = Loss.SpectralConsistencyLoss().to(device)
    SAMLoss = Loss.SpectralAngleLoss().to(device)
    print("âœ… å·²åŠ è½½31é€šé“ä¸“ç”¨æŸå¤±å‡½æ•°")

    # âœ… å…³é”®ä¿®å¤1: åˆ›å»ºä¸¤ä¸ªä¸åŒçš„baseæ¨¡å—
    with torch.no_grad():
        base_msi = model.base(in_channels=3)  # MSI: 3é€šé“ -> 64é€šé“
        base_hsi = model.base(in_channels=31)  # HSI: 31é€šé“ -> 64é€šé“
        hsi_MFE = model.FeatureExtractor()
        msi_MFE = model.FeatureExtractor()
        fusion_decoder = model.Decoder()
        PAFE = model.FeatureExtractor()
        decoder = model.Decoder()
        MN_hsi = model.Enhance()
        MN_msi = model.Enhance()
        HSIDP = model.DictionaryRepresentationModule()
        MSIDP = model.DictionaryRepresentationModule()
        ImageDeformation = model.ImageTransform()
        MHCSA_hsi = model.MHCSAB()
        MHCSA_msi = model.MHCSAB()
        fusion_module = model.FusionMoudle()

    # æ¨¡å‹è®­ç»ƒæ¨¡å¼+è®¾å¤‡è¿ç§»
    print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°GPU...")
    base_msi.train().to(device)
    base_hsi.train().to(device)
    hsi_MFE.train().to(device)
    msi_MFE.train().to(device)
    fusion_decoder.train().to(device)
    PAFE.train().to(device)
    decoder.train().to(device)
    HSIDP.train().to(device)
    MSIDP.train().to(device)
    MN_hsi.train().to(device)
    MN_msi.train().to(device)
    MHCSA_hsi.train().to(device)
    MHCSA_msi.train().to(device)
    fusion_module.train().to(device)

    # ========== ä¼˜åŒ–å™¨åˆå§‹åŒ– ==========
    print("âš™ï¸ æ­£åœ¨é…ç½®ä¼˜åŒ–å™¨...")
    optimizer_FE = torch.optim.Adam([
        {'params': base_msi.parameters()},  # âœ… ä¿®å¤2: åŒ…å«ä¸¤ä¸ªbase
        {'params': base_hsi.parameters()},
        {'params': hsi_MFE.parameters()},
        {'params': msi_MFE.parameters()},
        {'params': fusion_decoder.parameters()},
        {'params': PAFE.parameters()},
        {'params': decoder.parameters()},
        {'params': MN_hsi.parameters()},
        {'params': MN_msi.parameters()}
    ], lr=0.0002)

    optimizer_HSIDP = torch.optim.Adam(HSIDP.parameters(), lr=0.0008)
    optimizer_MSIDP = torch.optim.Adam(MSIDP.parameters(), lr=0.0008)
    optimizer_MHCSAhsi = torch.optim.Adam(MHCSA_hsi.parameters(), lr=args.args.LR)
    optimizer_MHCSAmsi = torch.optim.Adam(MHCSA_msi.parameters(), lr=args.args.LR)
    optimizer_FusionModule = torch.optim.Adam(fusion_module.parameters(), lr=0.0002)

    # âœ… ä¼˜åŒ–3: æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()
    print("âœ… å·²å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ï¼Œæ˜¾å­˜å ç”¨å°†å‡å°‘çº¦50%")


    # ========== è®­ç»ƒå‡½æ•°å®šä¹‰ ==========
    def train(epoch):
        # ========== âœ… å®Œæ•´çš„ç»´åº¦å’Œå‚æ•°éªŒè¯ ==========
        if epoch == 0:
            print(f"\n{'=' * 70}")
            print(f"ğŸ” Epoch 0 - å®Œæ•´å‚æ•°éªŒè¯:")
            print(f"{'=' * 70}")

        epoch_loss_HSIDP = []
        epoch_loss_MSIDP = []
        epoch_loss_same = []
        epoch_loss_fusion_total = []

        for step, x in enumerate(data_iter):
            # ========== æ•°æ®åŠ è½½ï¼ˆ6ä¸ªå¼ é‡ï¼‰==========
            hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2 = [
                item.to(device, non_blocking=True) for item in x
            ]

            # âœ… ç¬¬ä¸€ä¸ªbatchè¿›è¡Œå®Œæ•´éªŒè¯
            if step == 0 and epoch == 0:
                print(f"\nğŸ“Š 1. æ•°æ®ç»´åº¦éªŒè¯:")
                print(f"   Pair 1:")
                print(f"     - HSI:  {hsi_1.shape}  (æœŸæœ›: [1, 31, 16, 16])")
                print(f"     - MSI:  {msi_1.shape}  (æœŸæœ›: [1, 3, 512, 512])")
                print(f"     - GT:   {gt_1.shape}   (æœŸæœ›: [1, 31, 512, 512])")
                print(f"   Pair 2:")
                print(f"     - HSI:  {hsi_2.shape}  (æœŸæœ›: [1, 31, 16, 16])")
                print(f"     - MSI:  {msi_2.shape}  (æœŸæœ›: [1, 3, 512, 512])")
                print(f"     - GT:   {gt_2.shape}   (æœŸæœ›: [1, 31, 512, 512])")

                # âœ… éªŒè¯ç»´åº¦åŒ¹é…
                assert hsi_1.size(1) == 31, f"âŒ HSIé€šé“æ•°é”™è¯¯ï¼æœŸæœ›31ï¼Œå®é™…{hsi_1.size(1)}"
                assert msi_1.size(1) == 3, f"âŒ MSIé€šé“æ•°é”™è¯¯ï¼æœŸæœ›3ï¼Œå®é™…{msi_1.size(1)}"
                assert gt_1.size(1) == 31, f"âŒ GTé€šé“æ•°é”™è¯¯ï¼æœŸæœ›31ï¼Œå®é™…{gt_1.size(1)}"

                assert hsi_1.size(2) == 16 and hsi_1.size(3) == 16, \
                    f"âŒ HSIå°ºå¯¸é”™è¯¯ï¼æœŸæœ›16Ã—16ï¼Œå®é™…{hsi_1.size(2)}Ã—{hsi_1.size(3)}"
                assert msi_1.size(2) == 512 and msi_1.size(3) == 512, \
                    f"âŒ MSIå°ºå¯¸é”™è¯¯ï¼æœŸæœ›512Ã—512ï¼Œå®é™…{msi_1.size(2)}Ã—{msi_1.size(3)}"
                assert gt_1.size(2) == 512 and gt_1.size(3) == 512, \
                    f"âŒ GTå°ºå¯¸é”™è¯¯ï¼æœŸæœ›512Ã—512ï¼Œå®é™…{gt_1.size(2)}Ã—{gt_1.size(3)}"

                print(f"   âœ… æ‰€æœ‰ç»´åº¦éªŒè¯é€šè¿‡ï¼")

                # âœ… éªŒè¯æ•°å€¼èŒƒå›´
                print(f"\nğŸ“Š 2. æ•°å€¼èŒƒå›´éªŒè¯:")
                print(f"   - HSI:  min={hsi_1.min():.4f}, max={hsi_1.max():.4f}")
                print(f"   - MSI:  min={msi_1.min():.4f}, max={msi_1.max():.4f}")
                print(f"   - GT:   min={gt_1.min():.4f}, max={gt_1.max():.4f}")

                assert 0 <= hsi_1.min() and hsi_1.max() <= 1, "âŒ HSIæ•°å€¼èŒƒå›´åº”åœ¨[0,1]"
                assert 0 <= msi_1.min() and msi_1.max() <= 1, "âŒ MSIæ•°å€¼èŒƒå›´åº”åœ¨[0,1]"
                assert 0 <= gt_1.min() and gt_1.max() <= 1, "âŒ GTæ•°å€¼èŒƒå›´åº”åœ¨[0,1]"
                print(f"   âœ… æ‰€æœ‰æ•°å€¼èŒƒå›´æ­£å¸¸ï¼")

                # âœ… éªŒè¯çª—å£å‚æ•°
                print(f"\nğŸ“Š 3. çª—å£å‚æ•°éªŒè¯:")
                hsi_h, hsi_w = hsi_1.size(2), hsi_1.size(3)
                small_w = int(args.args.small_w_size)
                large_w = int(args.args.large_w_size)

                print(f"   - HSIå°ºå¯¸: {hsi_h}Ã—{hsi_w}")
                print(f"   - small_w_size: {small_w}")
                print(f"   - large_w_size: {large_w}")
                print(f"   - çª—å£æ•°é‡: {hsi_h // small_w}Ã—{hsi_w // small_w} = {(hsi_h // small_w) ** 2}ä¸ª")

                assert small_w <= hsi_h, \
                    f"âŒ small_w_size({small_w}) > HSIé«˜åº¦({hsi_h})ï¼"
                assert large_w > small_w, \
                    f"âŒ large_w_size({large_w}) åº”è¯¥ > small_w_size({small_w})ï¼"
                assert hsi_h % small_w == 0, \
                    f"âŒ HSIå°ºå¯¸({hsi_h})åº”è¯¥è¢«small_w_size({small_w})æ•´é™¤ï¼"

                print(f"   âœ… çª—å£å‚æ•°éªŒè¯é€šè¿‡ï¼")

                print(f"\n{'=' * 70}\n")
        """
        è®­ç»ƒå‡½æ•°
        å¤„ç†ä¸¤å¯¹é…å‡†æ•°æ®ï¼š
        - Pair 1: (hsi_1, msi_1, gt_1) - åŸå§‹é…å‡†å¯¹ï¼ˆæ¥è‡ªZ_reconst, Y_reconst, Xï¼‰
        - Pair 2: (hsi_2, msi_2, gt_2) - å½¢å˜é…å‡†å¯¹ï¼ˆæ¥è‡ªZ_deformed, Y_deformed, X_deformedï¼‰

        æ ¸å¿ƒæ€è·¯ï¼š
        1. åˆ†åˆ«æå–ä¸¤å¯¹é…å‡†æ•°æ®çš„ç‰¹å¾
        2. ç”¨Pair1çš„HSIç‰¹å¾ + Pair2çš„MSIç‰¹å¾ æ„é€ æœªé…å‡†å¯¹
        3. é€šè¿‡è·¨æ¨¡æ€å¯¹é½æ„ŸçŸ¥å­¦ä¹ å¯¹é½å…³ç³»
        4. ç”Ÿæˆæœ€ç»ˆçš„èåˆç»“æœ
        """
        # âœ… æ˜¾å­˜ç›‘æ§
        if epoch == 0:
            print(f"\nğŸ’¾ è®­ç»ƒå‰æ˜¾å­˜çŠ¶æ€:")
            print(f"   å·²åˆ†é…: {torch.cuda.memory_allocated() / 1024 ** 3:.2f} GB")
            print(f"   å·²ç¼“å­˜: {torch.cuda.memory_reserved() / 1024 ** 3:.2f} GB\n")

        epoch_loss_HSIDP = []
        epoch_loss_MSIDP = []
        epoch_loss_same = []
        epoch_loss_fusion_total = []

        for step, x in enumerate(data_iter):
            # ========== æ•°æ®åŠ è½½ï¼ˆ6ä¸ªå¼ é‡ï¼‰==========
            hsi_1, msi_1, gt_1, hsi_2, msi_2, gt_2 = [
                item.to(device, non_blocking=True) for item in x
            ]

            # âœ… æ‰“å°ç»´åº¦ï¼ˆä»…ç¬¬ä¸€ä¸ªbatchï¼‰
            if step == 0 and epoch == 0:
                print(f"\nâœ… æ•°æ®ç»´åº¦éªŒè¯:")
                print(f"   Pair 1:")
                print(f"     - HSI:  {hsi_1.shape}  (æœŸæœ›: [B, 31, 4, 4])")
                print(f"     - MSI:  {msi_1.shape}  (æœŸæœ›: [B, 3, 128, 128])")
                print(f"     - GT:   {gt_1.shape}   (æœŸæœ›: [B, 31, 128, 128])")
                print(f"   Pair 2:")
                print(f"     - HSI:  {hsi_2.shape}  (æœŸæœ›: [B, 31, 4, 4])")
                print(f"     - MSI:  {msi_2.shape}  (æœŸæœ›: [B, 3, 128, 128])")
                print(f"     - GT:   {gt_2.shape}   (æœŸæœ›: [B, 31, 128, 128])")

                # âœ… éªŒè¯GTç¡®å®æ˜¯31é€šé“
                assert gt_1.size(1) == 31, f"âŒ GTé€šé“æ•°é”™è¯¯ï¼æœŸæœ›31ï¼Œå®é™…{gt_1.size(1)}"
                assert gt_2.size(1) == 31, f"âŒ GTé€šé“æ•°é”™è¯¯ï¼æœŸæœ›31ï¼Œå®é™…{gt_2.size(1)}"
                print(f"âœ… æ‰€æœ‰ç»´åº¦åŒ¹é…ï¼\n")

            # ========== ä¸Šé‡‡æ ·HSIåˆ°MSIçš„åˆ†è¾¨ç‡ ==========
            hsi_1_up = F.interpolate(
                hsi_1,
                size=(msi_1.size(2), msi_1.size(3)),
                mode='bilinear',
                align_corners=False
            )
            hsi_2_up = F.interpolate(
                hsi_2,
                size=(msi_2.size(2), msi_2.size(3)),
                mode='bilinear',
                align_corners=False
            )

            # ========== æ··åˆç²¾åº¦è®­ç»ƒ ==========
            with autocast():
                # ====================================================================
                # é˜¶æ®µ1: åŸºç¡€ç‰¹å¾æå–ï¼ˆ64é€šé“ç»Ÿä¸€ç‰¹å¾ç©ºé—´ï¼‰
                # ====================================================================
                hsi_1_base = base_hsi(hsi_1_up)  # (B, 31, 128, 128) -> (B, 64, 128, 128)
                msi_1_base = base_msi(msi_1)  # (B, 3, 128, 128)  -> (B, 64, 128, 128)
                hsi_2_base = base_hsi(hsi_2_up)  # (B, 31, 128, 128) -> (B, 64, 128, 128)
                msi_2_base = base_msi(msi_2)  # (B, 3, 128, 128)  -> (B, 64, 128, 128)

                # é‡Šæ”¾ä¸éœ€è¦çš„ä¸Šé‡‡æ ·ç»“æœ
                del hsi_1_up, hsi_2_up
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ2: æ·±å±‚ç‰¹å¾æå–ï¼ˆç”¨äºèåˆé‡å»ºï¼‰
                # ====================================================================
                # Pair 1 çš„æ·±å±‚ç‰¹å¾
                hsi_1_fe = hsi_MFE(hsi_1_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_1_fe = msi_MFE(msi_1_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                simple_fusion_f_1 = hsi_1_fe + msi_1_fe
                fusion_image_1, fusion_f_1 = fusion_decoder(simple_fusion_f_1)  # -> (B, 31, 128, 128)

                # Pair 2 çš„æ·±å±‚ç‰¹å¾
                hsi_2_fe = hsi_MFE(hsi_2_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_2_fe = msi_MFE(msi_2_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                simple_fusion_f_2 = hsi_2_fe + msi_2_fe
                fusion_image_2, fusion_f_2 = fusion_decoder(simple_fusion_f_2)  # -> (B, 31, 128, 128)

                del simple_fusion_f_1, simple_fusion_f_2
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ3: PAFEç‰¹å¾æå–ï¼ˆç”¨äºå¯¹é½æ„ŸçŸ¥ï¼‰
                # ====================================================================
                # Pair 1 çš„PAFEç‰¹å¾
                hsi_1_f = PAFE(hsi_1_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_1_f = PAFE(msi_1_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                simple_fusion_pf_1 = hsi_1_f + msi_1_f
                fusion_pimage_1, fusion_pf_1 = decoder(simple_fusion_pf_1)  # -> (B, 31, 128, 128)

                # Pair 2 çš„PAFEç‰¹å¾
                hsi_2_f = PAFE(hsi_2_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_2_f = PAFE(msi_2_base)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                simple_fusion_pf_2 = hsi_2_f + msi_2_f
                fusion_pimage_2, fusion_pf_2 = decoder(simple_fusion_pf_2)  # -> (B, 31, 128, 128)

                del simple_fusion_pf_1, simple_fusion_pf_2
                del hsi_1_base, hsi_2_base, msi_1_base, msi_2_base
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ4: æ¨¡æ€å½’ä¸€åŒ–ï¼ˆModality Normalizationï¼‰
                # ====================================================================
                hsi_1_e_f = MN_hsi(hsi_1_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_1_e_f = MN_msi(msi_1_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                hsi_2_e_f = MN_hsi(hsi_2_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                msi_2_e_f = MN_msi(msi_2_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)

                # ====================================================================
                # é˜¶æ®µ5: å­—å…¸è¡¨ç¤ºæ¨¡å—ï¼ˆDictionary Representation Moduleï¼‰
                # ç”¨å¯å­¦ä¹ çš„æ¨¡æ€å­—å…¸è¡¥å¿å•æ¨¡æ€ç‰¹å¾ç¼ºå¤±çš„ä¿¡æ¯
                # ====================================================================
                HSIDP_hsi_1_f, _ = HSIDP(hsi_1_e_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                MSIDP_msi_1_f, _ = MSIDP(msi_1_e_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                HSIDP_hsi_2_f, _ = HSIDP(hsi_2_e_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)
                MSIDP_msi_2_f, _ = MSIDP(msi_2_e_f)  # (B, 64, 128, 128) -> (B, 64, 128, 128)

                del hsi_1_e_f, msi_1_e_f, hsi_2_e_f, msi_2_e_f
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ6: è·¨æ¨¡æ€å¯¹é½æ„ŸçŸ¥ï¼ˆCross-Modality Alignment Perceptionï¼‰
                # æ ¸å¿ƒï¼šæ„é€ æœªé…å‡†å¯¹ï¼ˆPair1çš„HSI + Pair2çš„MSIï¼‰
                # ====================================================================
                # ğŸ”¥ å…³é”®è®¾è®¡ï¼šç”¨Pair1çš„HSIä½œä¸ºå‚è€ƒï¼ˆfixedï¼‰ï¼ŒPair2çš„MSIä½œä¸ºç§»åŠ¨ï¼ˆmovingï¼‰
                # è¿™æ ·å¯ä»¥å­¦ä¹ å¦‚ä½•å°†æœªé…å‡†çš„MSIå¯¹é½åˆ°HSI
                fixed_DP = HSIDP_hsi_1_f  # å‚è€ƒå›¾åƒç‰¹å¾ï¼ˆæ¥è‡ªPair1ï¼‰
                moving_DP = MSIDP_msi_2_f  # ç§»åŠ¨å›¾åƒç‰¹å¾ï¼ˆæ¥è‡ªPair2ï¼‰

                # çª—å£åˆ†å‰²
                moving_DP_lw = model.df_window_partition(
                    moving_DP,
                    args.args.large_w_size,  # 12
                    args.args.small_w_size  # 8
                )  # -> (num_windows, B, 64, 12, 12)

                fixed_DP_sw = model.window_partition(
                    fixed_DP,
                    args.args.small_w_size,  # 8
                    args.args.small_w_size  # 8
                )  # -> (num_windows, B, 64, 8, 8)

                # è®¡ç®—å¯¹é½æ„ŸçŸ¥çŸ©é˜µ
                correspondence_matrixs = model.CMAP(
                    fixed_DP_sw,  # å‚è€ƒçª—å£
                    moving_DP_lw,  # ç§»åŠ¨çª—å£
                    MHCSA_hsi,  # HSIçš„å¤šå¤´è·¨å°ºåº¦æ³¨æ„åŠ›
                    MHCSA_msi,  # MSIçš„å¤šå¤´è·¨å°ºåº¦æ³¨æ„åŠ›
                    True  # HSIä½œä¸ºå‚è€ƒ
                )  # -> (num_windows, B, 8*8, 12*12)

                del fixed_DP_sw, moving_DP_lw
                torch.cuda.empty_cache()

                # ====================================================================
                # é˜¶æ®µ7: ç‰¹å¾é‡ç»„å’Œæœ€ç»ˆèåˆ
                # æ ¹æ®å¯¹é½çŸ©é˜µé‡ç»„MSIç‰¹å¾ï¼Œä½¿å…¶ä¸HSIå¯¹é½
                # ====================================================================
                msi_2_f_sample = model.feature_reorganization(
                    correspondence_matrixs,  # å¯¹é½çŸ©é˜µ
                    msi_2_fe  # Pair2çš„MSIç‰¹å¾
                )  # -> (B, 64, 128, 128) - å¯¹é½åçš„MSIç‰¹å¾

                # æœ€ç»ˆèåˆï¼šPair1çš„HSI + å¯¹é½åçš„Pair2çš„MSI
                fusion_image_sample = fusion_module(
                    hsi_1_fe,  # Pair1çš„HSIç‰¹å¾
                    msi_2_f_sample  # å¯¹é½åçš„Pair2çš„MSIç‰¹å¾
                )  # -> (B, 31, 128, 128)

                # ====================================================================
                # é˜¶æ®µ8: æŸå¤±è®¡ç®—
                # ====================================================================

                # 8.1 åŸºç¡€èåˆæŸå¤±ï¼ˆç›‘ç£ä¸¤å¯¹é…å‡†æ•°æ®çš„èåˆè´¨é‡ï¼‰
                # âœ… ä¿®æ­£ï¼šä¼ å…¥æ­£ç¡®çš„ (hsi, msi, fusion) ä¸‰å…ƒç»„
                loss_fusion_1 = (
                        Lgrad(hsi_1, msi_1, fusion_image_1) +  # 31é€šé“æ¢¯åº¦æŸå¤±
                        Loss.Loss_intensity(hsi_1, msi_1, fusion_image_1) +  # 31é€šé“å¼ºåº¦æŸå¤±
                        Lgrad(hsi_1, msi_1, fusion_pimage_1) +
                        Loss.Loss_intensity(hsi_1, msi_1, fusion_pimage_1) +
                        0.5 * SpectralLoss(fusion_image_1, gt_1)  # âœ… æ–°å¢ï¼šå…‰è°±ä¸€è‡´æ€§æŸå¤±
                )

                loss_fusion_2 = (
                        Lgrad(hsi_2, msi_2, fusion_image_2) +
                        Loss.Loss_intensity(hsi_2, msi_2, fusion_image_2) +
                        Lgrad(hsi_2, msi_2, fusion_pimage_2) +
                        Loss.Loss_intensity(hsi_2, msi_2, fusion_pimage_2) +
                        0.5 * SpectralLoss(fusion_image_2, gt_2)  # âœ… æ–°å¢
                )

                loss_0 = loss_fusion_1 + loss_fusion_2

                # 8.2 å­—å…¸ä¸€è‡´æ€§æŸå¤±ï¼ˆç¡®ä¿å­—å…¸è¡¥å¿åçš„ç‰¹å¾ä¸èåˆç‰¹å¾ä¸€è‡´ï¼‰
                loss_HSIDP = (
                        - CC(HSIDP_hsi_1_f, fusion_pf_1.detach())
                        - CC(HSIDP_hsi_2_f, fusion_pf_2.detach())
                )

                loss_MSIDP = (
                        - CC(MSIDP_msi_1_f, fusion_pf_1.detach())
                        - CC(MSIDP_msi_2_f, fusion_pf_2.detach())
                )

                # 8.3 æ¨¡æ€ä¸€è‡´æ€§æŸå¤±ï¼ˆç¡®ä¿HSIå’ŒMSIçš„å­—å…¸è¡¥å¿ç»“æœä¸€è‡´ï¼‰
                loss_same = (
                        F.mse_loss(HSIDP_hsi_1_f, MSIDP_msi_1_f) +
                        F.mse_loss(HSIDP_hsi_2_f, MSIDP_msi_2_f)
                )

                loss_1 = 2 * (loss_HSIDP + loss_MSIDP + 0.5 * loss_same)

                # 8.4 å¯¹é½èåˆæŸå¤±
                # âœ… ä¿®æ­£ï¼šç”¨ hsi_1 å’Œ msi_2 ç›‘ç£ï¼ˆå› ä¸ºæ˜¯ hsi_1 + aligned(msi_2) çš„èåˆï¼‰
                loss_2 = (
                        Lgrad(hsi_1, msi_2, fusion_image_sample) +
                        Loss.Loss_intensity(hsi_1, msi_2, fusion_image_sample)
                )
                # 8.5 å¯¹é½ç›‘ç£æŸå¤±ï¼ˆæš‚æ—¶ç¦ç”¨ï¼Œéœ€è¦ä¿å­˜index_ræ‰èƒ½å¯ç”¨ï¼‰
                # å¦‚æœä½ åœ¨generate_deformed_gt.pyä¸­ä¿å­˜äº†å˜æ¢çŸ©é˜µï¼Œå¯ä»¥å¯ç”¨è¿™éƒ¨åˆ†
                # loss_correspondence_matrix, loss_correspondence_matrix_1 = Lcorrespondence(
                #     correspondence_matrixs, index_r
                # )
                # loss_3 = 4 * (loss_correspondence_matrix + loss_correspondence_matrix_1)

                # æ€»æŸå¤±
                loss = loss_0 + loss_1 + loss_2  # + loss_3 (éœ€è¦index_ræ—¶å¯ç”¨)

            # ========== åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰==========
            optimizer_HSIDP.zero_grad()
            optimizer_MSIDP.zero_grad()
            optimizer_MHCSAhsi.zero_grad()
            optimizer_MHCSAmsi.zero_grad()
            optimizer_FusionModule.zero_grad()
            optimizer_FE.zero_grad()

            scaler.scale(loss).backward()
            scaler.step(optimizer_FE)
            scaler.step(optimizer_HSIDP)
            scaler.step(optimizer_MSIDP)
            scaler.step(optimizer_MHCSAhsi)
            scaler.step(optimizer_MHCSAmsi)
            scaler.step(optimizer_FusionModule)
            scaler.update()



            # ========== è®°å½•æŸå¤± ==========
            epoch_loss_HSIDP.append(loss_HSIDP.item())
            epoch_loss_MSIDP.append(loss_MSIDP.item())
            epoch_loss_same.append(loss_same.item())
            epoch_loss_fusion_total.append(loss.item())

            # ========== ä¿å­˜æ¨¡å‹ ==========
            if ((epoch + 1) == args.args.Epoch and (step + 1) % iter_num == 0) or \
                    (epoch % args.args.save_model_num == 0 and (step + 1) % iter_num == 0):
                ckpts = {
                    "bfe_msi": base_msi.state_dict(),
                    "bfe_hsi": base_hsi.state_dict(),
                    "msi_mfe": msi_MFE.state_dict(),
                    "hsi_mfe": hsi_MFE.state_dict(),
                    "pafe": PAFE.state_dict(),
                    "fusion_decoder": fusion_decoder.state_dict(),
                    "decoder": decoder.state_dict(),
                    "mn_msi": MN_msi.state_dict(),
                    "mn_hsi": MN_hsi.state_dict(),
                    "msi_dgfp": MSIDP.state_dict(),
                    "hsi_dgfp": HSIDP.state_dict(),
                    "mhcsab_msi": MHCSA_msi.state_dict(),
                    "mhcsab_hsi": MHCSA_hsi.state_dict(),
                    "fusion_block": fusion_module.state_dict(),
                }
                save_dir = '{:s}/epoch{:d}_iter{:d}.pth'.format(save_model_dir, epoch, step + 1)
                torch.save(ckpts, save_dir)
                print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_dir}")



            # âœ… æ¯10æ­¥æ‰“å°æ˜¾å­˜ï¼ˆå¯é€‰ï¼‰
            if step % 10 == 0:
                print(f"Step {step}/{iter_num} - æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024 ** 3:.2f} GB")

        # ========== æ‰“å°epochç»Ÿè®¡ä¿¡æ¯ ==========
        epoch_loss_HSIDP_mean = np.mean(epoch_loss_HSIDP)
        epoch_loss_MSIDP_mean = np.mean(epoch_loss_MSIDP)
        epoch_loss_same_mean = np.mean(epoch_loss_same)
        epoch_loss_fusion_mean = np.mean(epoch_loss_fusion_total)

        # âœ… æ–°å¢ï¼šè®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªbatchçš„ç»“æœï¼‰
        with torch.no_grad():
            # è®¡ç®—PSNR
            mse = F.mse_loss(fusion_image_sample, gt_1)
            psnr = 10 * torch.log10(1.0 / mse)

            # è®¡ç®—SAMï¼ˆå…‰è°±è§’è·ç¦»ï¼‰
            # å°†ç©ºé—´ç»´åº¦å±•å¹³: (B, 31, H, W) -> (B, 31, H*W)
            pred_flat = fusion_image_sample.view(fusion_image_sample.size(0), fusion_image_sample.size(1), -1)
            target_flat = gt_1.view(gt_1.size(0), gt_1.size(1), -1)

            # è®¡ç®—å†…ç§¯å’Œæ¨¡é•¿
            dot_product = torch.sum(pred_flat * target_flat, dim=1)  # (B, H*W)
            pred_norm = torch.norm(pred_flat, dim=1) + 1e-8
            target_norm = torch.norm(target_flat, dim=1) + 1e-8

            # è®¡ç®—coså€¼å¹¶è½¬æ¢ä¸ºè§’åº¦
            cos_theta = dot_product / (pred_norm * target_norm)
            cos_theta = torch.clamp(cos_theta, -1.0, 1.0)
            sam = torch.acos(cos_theta).mean() * 180 / np.pi  # è½¬æ¢ä¸ºåº¦æ•°

        print()
        print(f"ğŸ“Š Epoch {epoch} ç»Ÿè®¡:")
        print(f"   - æ€»æŸå¤±(Total Loss):     {epoch_loss_fusion_mean:.6f}")
        print(f"   - HSIå­—å…¸æŸå¤±(HSIDP):      {epoch_loss_HSIDP_mean:.6f}")
        print(f"   - MSIå­—å…¸æŸå¤±(MSIDP):      {epoch_loss_MSIDP_mean:.6f}")
        print(f"   - æ¨¡æ€ä¸€è‡´æ€§æŸå¤±(Same):    {epoch_loss_same_mean:.6f}")
        with torch.no_grad():
            spectral_loss_val = SpectralLoss(fusion_image_sample, gt_1)
            sam_loss_val = SAMLoss(fusion_image_sample, gt_1)
            print(f"   - å…‰è°±ä¸€è‡´æ€§æŸå¤±:          {spectral_loss_val.item():.6f}")
            print(f"   - å…‰è°±è§’æŸå¤±(SAM):         {sam_loss_val.item():.6f}")

        print(f"   ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡:")
        print(f"      - PSNR: {psnr.item():.4f} dB")
        print(f"      - SAM:  {sam.item():.4f}Â°")



    """
        è¾“å…¥: 6ä¸ªå¼ é‡
â”œâ”€â”€ Pair 1: hsi_1, msi_1, gt_1  (æ¥è‡ª Z_reconst, Y_reconst, X)
â””â”€â”€ Pair 2: hsi_2, msi_2, gt_2  (æ¥è‡ª Z_deformed, Y_deformed, X_deformed)

æ ¸å¿ƒè®¾è®¡:
â”œâ”€â”€ ç”¨Pair1å’ŒPair2åˆ†åˆ«è®­ç»ƒåŸºç¡€èåˆèƒ½åŠ›
â””â”€â”€ æ„é€ æœªé…å‡†å¯¹: hsi_1 + msi_2 (è·¨Pairæ„é€ )
    â””â”€â”€ é€šè¿‡CMAPå­¦ä¹ å¯¹é½å…³ç³»
        â””â”€â”€ ç”Ÿæˆæœ€ç»ˆå¯¹é½èåˆç»“æœ
        """



    # ========== å¯åŠ¨è®­ç»ƒå¾ªç¯ ==========
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“Œ è®­ç»ƒå‚æ•°:")
    print(f"   - Epochs: {args.args.Epoch}")
    print(f"   - Batch Size: {args.args.batch_size}")
    print(f"   - è®­ç»ƒæ ·æœ¬æ•°: {len(dataset)}")
    print(f"   - æ¯epochè¿­ä»£æ•°: {iter_num}")
    print(f"   - å›¾åƒå°ºå¯¸: {args.args.img_size}Ã—{args.args.img_size}")
    print(f"   - æ··åˆç²¾åº¦: å·²å¯ç”¨\n")

    for epoch in tqdm(range(args.args.Epoch), desc="è®­ç»ƒè¿›åº¦"):
        if epoch < args.args.Warm_epoch:
            warmup_learning_rate(optimizer_MHCSAhsi, epoch)
            warmup_learning_rate(optimizer_MHCSAmsi, epoch)
        else:
            adjust_learning_rate(optimizer_MHCSAhsi, epoch)
            adjust_learning_rate(optimizer_MHCSAmsi, epoch)

        train(epoch)

    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")