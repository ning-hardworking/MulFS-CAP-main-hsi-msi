# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„ HSI/MSI é€€åŒ–ç½‘ç»œè®­ç»ƒå’Œæ•°æ®ç”Ÿæˆè„šæœ¬
é€‚é… MulFS-CAP ä» IR-VIS åˆ° HSI-MSI çš„è¿ç§»

æ•°æ®æµç¨‹ï¼š
1. è®­ç»ƒé€€åŒ–ç½‘ç»œï¼šX/ + Z/ + Y/ â†’ å­¦ä¹  hsi_degen å’Œ msi_degen
2. ç”ŸæˆPair1æ•°æ®ï¼šX/ â†’ Z_reconst/ + Y_reconst/ (åŸå§‹é…å‡†å¯¹)
3. ç”ŸæˆPair2æ•°æ®ï¼šX_deformed/ â†’ Z_deformed/ + Y_deformed/ (å½¢å˜é…å‡†å¯¹)
"""

import os
import gc
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingLR
import numpy as np
import scipy.io as sio
from pathlib import Path

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

# ====================== 1. é…ç½®å‚æ•° ======================
ROOT_PATH = r"D:\datas\CAVEdata"

# åŸå§‹æ•°æ®ï¼ˆæ•°æ®é›†æä¾›ï¼‰
GT_RAW_DIR = os.path.join(ROOT_PATH, "X")  # åŸå§‹GT (512Ã—512Ã—31)
HSI_RAW_DIR = os.path.join(ROOT_PATH, "Z")  # åŸå§‹HSI (16Ã—16Ã—31)
MSI_RAW_DIR = os.path.join(ROOT_PATH, "Y")  # åŸå§‹MSI (512Ã—512Ã—3)

# å½¢å˜GTï¼ˆgenerate_deformed_gt.pyç”Ÿæˆï¼‰
GT_DEFORMED_DIR = os.path.join(ROOT_PATH, "X_deformed")  # å½¢å˜GT (512Ã—512Ã—31)

# è¾“å‡ºç›®å½•ï¼ˆæœ¬è„šæœ¬ç”Ÿæˆï¼‰
Z_RECONST_SAVE = os.path.join(ROOT_PATH, "Z_reconst")  # é‡å»ºHSI (Pair1)
Y_RECONST_SAVE = os.path.join(ROOT_PATH, "Y_reconst")  # é‡å»ºMSI (Pair1)
HSI_DEFORMED_SAVE = os.path.join(ROOT_PATH, "Z_deformed")  # å½¢å˜HSI (Pair2)
MSI_DEFORMED_SAVE = os.path.join(ROOT_PATH, "Y_deformed")  # å½¢å˜MSI (Pair2)

# æƒé‡ä¿å­˜è·¯å¾„
WEIGHT_SAVE_PATH = ROOT_PATH

# æ•°æ®é›†å‚æ•°ï¼ˆCAVEæ•°æ®é›†å›ºå®šå‚æ•°ï¼Œä¸è¦ä¿®æ”¹ï¼‰
GT_SIZE = 512  # GTå›¾åƒå°ºå¯¸
HSI_SIZE = 16  # HSIå›¾åƒå°ºå¯¸
MSI_BANDS = 3  # MSIé€šé“æ•°
GT_BANDS = 31  # GT/HSIé€šé“æ•°
DOWNSAMPLE_SCALE = GT_SIZE // HSI_SIZE  # ä¸‹é‡‡æ ·å€ç‡ï¼š32

# è®­ç»ƒå‚æ•°
EPOCHS = 200
LR = 1e-4
WEIGHT_DECAY = 1e-5

# è®¾å¤‡é…ç½®
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

print("=" * 70)
print("ğŸš€ MulFS-CAP HSI-MSI é€€åŒ–ç½‘ç»œè®­ç»ƒå’Œæ•°æ®ç”Ÿæˆ")
print("=" * 70)
print(f"âœ… è®­ç»ƒè®¾å¤‡: {DEVICE}")
print(f"âœ… ä¸‹é‡‡æ ·å€ç‡: {DOWNSAMPLE_SCALE}å€ (512 â†’ 16)")
print(f"âœ… GT: {GT_SIZE}Ã—{GT_SIZE}Ã—{GT_BANDS}")
print(f"âœ… HSI: {HSI_SIZE}Ã—{HSI_SIZE}Ã—{GT_BANDS}")
print(f"âœ… MSI: {GT_SIZE}Ã—{GT_SIZE}Ã—{MSI_BANDS}")
print("=" * 70 + "\n")


# ====================== 2. å™ªå£°æ¨¡å— ======================
class GaussianNoise(nn.Module):
    """é«˜æ–¯å™ªå£°"""

    def __init__(self, sigma=0.001):
        super().__init__()
        self.sigma = sigma

    def forward(self, x):
        if self.training:
            return x + torch.randn_like(x) * self.sigma
        return x


class PoissonNoise(nn.Module):
    """æ³Šæ¾å™ªå£°"""

    def forward(self, x):
        if self.training:
            return torch.poisson(x.clamp(min=1e-8)) / x.clamp(min=1e-8) * x
        return x


# ====================== 3. å…‰è°±æ³¨æ„åŠ›æ¨¡å— ======================
class SpectralAttention(nn.Module):
    """å…‰è°±é€šé“æ³¨æ„åŠ›"""

    def __init__(self, in_channels):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(in_channels, in_channels // 4, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // 4, in_channels, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)


# ====================== 4. æ®‹å·®å— ======================
class ResidualBlock(nn.Module):
    """å¸¦GroupNormçš„æ®‹å·®å—"""

    def __init__(self, in_channels, groups=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, 1, 1, groups=groups, bias=False)
        self.norm1 = nn.GroupNorm(groups, in_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, 1, 1, groups=groups, bias=False)
        self.norm2 = nn.GroupNorm(groups, in_channels)

        # åˆå§‹åŒ–
        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_out', nonlinearity='relu')

    def forward(self, x):
        residual = x
        out = self.relu(self.norm1(self.conv1(x)))
        out = self.norm2(self.conv2(out))
        return self.relu(out + residual)


# ====================== 5. HSI é€€åŒ–ç½‘ç»œ ======================
class DeepHSIDegenerator(nn.Module):
    """
    æ·±åº¦HSIé€€åŒ–ç½‘ç»œ
    GT(31, 512, 512) â†’ HSI(31, 16, 16)

    é€€åŒ–è¿‡ç¨‹ï¼š
    1. ç‰¹å¾æå–ï¼ˆä¿æŒå…‰è°±ä¿¡æ¯ï¼‰
    2. ç©ºé—´æ¨¡ç³Šï¼ˆæ¨¡æ‹Ÿå…‰å­¦ç³»ç»Ÿçš„ç‚¹æ‰©æ•£å‡½æ•°ï¼‰
    3. ä¸‹é‡‡æ ·ï¼ˆ32å€ï¼Œ512 â†’ 16ï¼‰
    4. å™ªå£°æ³¨å…¥ï¼ˆæ³Šæ¾å™ªå£° + é«˜æ–¯å™ªå£°ï¼‰
    """

    def __init__(self, in_bands=31, out_bands=31, scale=32):
        super().__init__()
        self.groups = 1  # ä½¿ç”¨å…¨å·ç§¯ï¼ˆä¸åˆ†ç»„ï¼‰ä»¥ä¿æŒå…‰è°±ç›¸å…³æ€§

        # åˆå§‹å·ç§¯
        self.init_conv = nn.Conv2d(in_bands, in_bands, 3, 1, 1, groups=self.groups, bias=False)

        # æ®‹å·®å—ï¼ˆä¿æŒå…‰è°±ç‰¹å¾ï¼‰
        self.res1 = ResidualBlock(in_bands, self.groups)
        self.res2 = ResidualBlock(in_bands, self.groups)

        # ç©ºé—´æ¨¡ç³Šï¼ˆæ¨¡æ‹Ÿå…‰å­¦ç³»ç»Ÿçš„ç‚¹æ‰©æ•£å‡½æ•°ï¼‰
        self.blur = nn.Sequential(
            nn.Conv2d(in_bands, in_bands, 5, 1, 2, groups=self.groups, bias=False),
            nn.Conv2d(in_bands, in_bands, 7, 1, 3, groups=self.groups, bias=False)
        )

        # ä¸‹é‡‡æ ·ï¼ˆ32å€ï¼š2^5 = 32ï¼‰
        self.down_sample = nn.Sequential(
            nn.AvgPool2d(2, 2),  # 512 â†’ 256
            nn.AvgPool2d(2, 2),  # 256 â†’ 128
            nn.AvgPool2d(2, 2),  # 128 â†’ 64
            nn.AvgPool2d(2, 2),  # 64 â†’ 32
            nn.AvgPool2d(2, 2)  # 32 â†’ 16
        )

        # å™ªå£°
        self.noise = nn.Sequential(
            PoissonNoise(),
            GaussianNoise(0.001)
        )

        # åˆå§‹åŒ–
        nn.init.kaiming_normal_(self.init_conv.weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.blur[0].weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.blur[1].weight, mode='fan_out', nonlinearity='relu')

    def forward(self, x):
        """
        è¾“å…¥: (B, 31, 512, 512)
        è¾“å‡º: (B, 31, 16, 16)
        """
        x = self.init_conv(x)
        x = self.res1(x)
        x = self.res2(x)
        x = self.blur(x)
        x = self.down_sample(x)
        x = self.noise(x)
        return x.clamp(0, 1)


# ====================== 6. MSI é€€åŒ–ç½‘ç»œ ======================
class DeepMSIDegenerator(nn.Module):
    """
    æ·±åº¦MSIé€€åŒ–ç½‘ç»œ
    GT(31, 512, 512) â†’ MSI(3, 512, 512)

    é€€åŒ–è¿‡ç¨‹ï¼š
    1. ç‰¹å¾æå–ï¼ˆä¿æŒç©ºé—´åˆ†è¾¨ç‡ï¼‰
    2. å…‰è°±æ³¨æ„åŠ›ï¼ˆé€‰æ‹©é‡è¦çš„å…‰è°±ä¿¡æ¯ï¼‰
    3. å…‰è°±é™ç»´ï¼ˆ31é€šé“ â†’ 3é€šé“ï¼Œæ¨¡æ‹ŸRGBä¼ æ„Ÿå™¨ï¼‰
    4. ç©ºé—´å¹³æ»‘ï¼ˆè½»å¾®æ¨¡ç³Šï¼‰
    5. å™ªå£°æ³¨å…¥ï¼ˆé«˜æ–¯å™ªå£°ï¼‰
    """

    def __init__(self, in_bands=31, out_bands=3):
        super().__init__()

        # åˆå§‹å·ç§¯ï¼ˆæ·±åº¦å¯åˆ†ç¦»ï¼‰
        self.init_conv = nn.Conv2d(in_bands, in_bands, 3, 1, 1, groups=in_bands, bias=False)

        # æ®‹å·®å—ï¼ˆæå–ç‰¹å¾ï¼‰
        self.res1 = ResidualBlock(in_bands, groups=1)

        # å…‰è°±æ³¨æ„åŠ›ï¼ˆé€‰æ‹©é‡è¦çš„å…‰è°±ä¿¡æ¯ï¼‰
        self.attention = SpectralAttention(in_bands)

        # å…‰è°±é™ç»´ï¼ˆ31 â†’ 3ï¼Œæ¨¡æ‹ŸRGBä¼ æ„Ÿå™¨çš„å…‰è°±å“åº”å‡½æ•°ï¼‰
        self.spectral_conv = nn.Conv2d(in_bands, out_bands, 1, 1, 0, bias=False)

        # ç©ºé—´å¹³æ»‘ï¼ˆè½»å¾®æ¨¡ç³Šï¼Œä¿æŒç©ºé—´åˆ†è¾¨ç‡ï¼‰
        self.spatial_smooth = nn.Conv2d(
            out_bands, out_bands, 3, 1, 2,
            dilation=2, groups=out_bands, bias=False
        )

        # å™ªå£°
        self.noise = GaussianNoise(0.0005)

        # åˆå§‹åŒ–
        nn.init.kaiming_normal_(self.init_conv.weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.spectral_conv.weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.spatial_smooth.weight, mode='fan_out', nonlinearity='relu')

    def forward(self, x):
        """
        è¾“å…¥: (B, 31, 512, 512)
        è¾“å‡º: (B, 3, 512, 512)
        """
        x = self.init_conv(x)
        x = self.res1(x)
        x = self.attention(x)
        x = self.spectral_conv(x)
        x = self.spatial_smooth(x)
        x = self.noise(x)
        return x.clamp(0, 1)


# ====================== 7. æŸå¤±å‡½æ•° ======================
def total_loss(pred_hsi, real_hsi, pred_msi, real_msi):
    """
    ç»„åˆæŸå¤±ï¼šL1 + MSE

    Args:
        pred_hsi: é¢„æµ‹çš„HSI (B, 31, 16, 16)
        real_hsi: çœŸå®çš„HSI (B, 31, 16, 16)
        pred_msi: é¢„æµ‹çš„MSI (B, 3, 512, 512)
        real_msi: çœŸå®çš„MSI (B, 3, 512, 512)

    Returns:
        loss: æ ‡é‡
    """
    # HSIæŸå¤±
    hsi_l1 = nn.L1Loss()(pred_hsi, real_hsi)
    hsi_mse = nn.MSELoss()(pred_hsi, real_hsi)

    # MSIæŸå¤±
    msi_l1 = nn.L1Loss()(pred_msi, real_msi)
    msi_mse = nn.MSELoss()(pred_msi, real_msi)

    # ç»„åˆï¼ˆL1æƒé‡æ›´é«˜ï¼Œæ›´å…³æ³¨ç»†èŠ‚ï¼‰
    loss = 0.7 * (hsi_l1 + msi_l1) + 0.3 * (hsi_mse + msi_mse)

    return loss


# ====================== 8. æ•°æ®åŠ è½½å‡½æ•° ======================
def load_mat_data(file_path):
    """
    åŠ è½½.matæ–‡ä»¶å¹¶æ ‡å‡†åŒ–

    Args:
        file_path: .matæ–‡ä»¶è·¯å¾„

    Returns:
        img_np: numpyæ•°ç»„ (C, H, W)ï¼Œå·²å½’ä¸€åŒ–åˆ°[0,1]
    """
    mat_data = sio.loadmat(str(file_path))
    mat_values = [v for k, v in mat_data.items() if not k.startswith('__')]
    img_np = mat_values[0].astype(np.float32)

    # ğŸ”¥ è‡ªåŠ¨é€‚é…ç»´åº¦ï¼šæ‰¾åˆ°é€šé“æ•°=31çš„ç»´åº¦ï¼Œç§»åˆ°ç¬¬0ä½
    if img_np.ndim == 3:
        # æ‰¾åˆ°ç­‰äº31çš„ç»´åº¦ï¼ˆé€šé“ç»´åº¦ï¼‰
        channel_axis = None
        for axis in range(3):
            if img_np.shape[axis] == GT_BANDS:
                channel_axis = axis
                break

        # å¦‚æœæ‰¾åˆ°äº†ï¼Œç§»åˆ°ç¬¬0ä½
        if channel_axis is not None:
            img_np = np.moveaxis(img_np, source=channel_axis, destination=0)
        # å¦åˆ™ï¼Œå‡è®¾æœ€åä¸€ç»´æ˜¯é€šé“
        elif img_np.shape[-1] < img_np.shape[0] and img_np.shape[-1] < img_np.shape[1]:
            img_np = np.transpose(img_np, (2, 0, 1))

    # æ ‡å‡†åŒ–åˆ°[0,1]
    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)

    return img_np


# ====================== 9. è®­ç»ƒé€€åŒ–ç½‘ç»œ ======================
def train_deep_degenerators():
    """
    è®­ç»ƒæ·±åº¦é€€åŒ–ç½‘ç»œ

    Returns:
        hsi_degen: è®­ç»ƒå¥½çš„HSIé€€åŒ–ç½‘ç»œ
        msi_degen: è®­ç»ƒå¥½çš„MSIé€€åŒ–ç½‘ç»œ
    """
    print("\n" + "=" * 70)
    print("ğŸ”¥ å¼€å§‹è®­ç»ƒæ·±åº¦é€€åŒ–ç½‘ç»œ")
    print("=" * 70)

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(WEIGHT_SAVE_PATH, exist_ok=True)

    # åˆå§‹åŒ–ç½‘ç»œ
    hsi_degen = DeepHSIDegenerator(GT_BANDS, GT_BANDS, DOWNSAMPLE_SCALE).to(DEVICE)
    msi_degen = DeepMSIDegenerator(GT_BANDS, MSI_BANDS).to(DEVICE)

    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(
        list(hsi_degen.parameters()) + list(msi_degen.parameters()),
        lr=LR,
        weight_decay=WEIGHT_DECAY
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)

    # åŠ è½½æ•°æ®
    valid_suffix = ['.mat', '.MAT']
    gt_file_paths = sorted([p for p in Path(GT_RAW_DIR).glob("*.*") if p.suffix in valid_suffix])

    print(f"âœ… æ‰¾åˆ° {len(gt_file_paths)} ç»„è®­ç»ƒæ•°æ®")
    print(f"âœ… è®­ç»ƒå‚æ•°: Epochs={EPOCHS}, LR={LR}, Batch=1")
    print(f"âœ… ä¼˜åŒ–å™¨: Adam, å­¦ä¹ ç‡è°ƒåº¦: CosineAnnealing")
    print("-" * 70)

    # è®­ç»ƒå¾ªç¯
    hsi_degen.train()
    msi_degen.train()

    for epoch in range(EPOCHS):
        epoch_loss = 0.0

        for idx, gt_path in enumerate(gt_file_paths):
            fname = gt_path.name
            hsi_path = os.path.join(HSI_RAW_DIR, fname)
            msi_path = os.path.join(MSI_RAW_DIR, fname)

            # æ£€æŸ¥é…å¯¹æ–‡ä»¶
            if not os.path.exists(hsi_path) or not os.path.exists(msi_path):
                print(f"âš ï¸ è·³è¿‡ {fname}ï¼šç¼ºå°‘é…å¯¹æ–‡ä»¶")
                continue

            try:
                # åŠ è½½æ•°æ®
                gt_np = load_mat_data(gt_path)  # (31, 512, 512)
                hsi_np = load_mat_data(hsi_path)  # (31, 16, 16)
                msi_np = load_mat_data(msi_path)  # (3, 512, 512)

                # è½¬æ¢ä¸ºå¼ é‡
                gt_tensor = torch.from_numpy(gt_np).unsqueeze(0).to(DEVICE)
                hsi_tensor = torch.from_numpy(hsi_np).unsqueeze(0).to(DEVICE)
                msi_tensor = torch.from_numpy(msi_np).unsqueeze(0).to(DEVICE)

                # ç¬¬ä¸€ä¸ªæ ·æœ¬æ—¶æ‰“å°ç»´åº¦éªŒè¯
                if idx == 0 and epoch == 0:
                    print(f"âœ… æ•°æ®ç»´åº¦éªŒè¯:")
                    print(f"   GT:  {gt_tensor.shape}")
                    print(f"   HSI: {hsi_tensor.shape}")
                    print(f"   MSI: {msi_tensor.shape}")

                    # å‰å‘ä¼ æ’­éªŒè¯
                    with torch.no_grad():
                        pred_hsi_test = hsi_degen(gt_tensor)
                        pred_msi_test = msi_degen(gt_tensor)
                    print(f"   é¢„æµ‹HSI: {pred_hsi_test.shape}")
                    print(f"   é¢„æµ‹MSI: {pred_msi_test.shape}")
                    print(f"âœ… æ‰€æœ‰ç»´åº¦åŒ¹é…ï¼\n")

                # å‰å‘ä¼ æ’­
                pred_hsi = hsi_degen(gt_tensor)
                pred_msi = msi_degen(gt_tensor)

                # è®¡ç®—æŸå¤±
                loss = total_loss(pred_hsi, hsi_tensor, pred_msi, msi_tensor)

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()

                # æ¸…ç†å†…å­˜
                del gt_tensor, hsi_tensor, msi_tensor, pred_hsi, pred_msi
                gc.collect()

            except Exception as e:
                print(f"âŒ å¤„ç† {fname} æ—¶å‡ºé”™: {str(e)}")
                continue

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()

        # æ‰“å°è®­ç»ƒè¿›åº¦
        if (epoch + 1) % 10 == 0:
            avg_loss = epoch_loss / len(gt_file_paths)
            current_lr = optimizer.param_groups[0]['lr']
            print(f"Epoch [{epoch + 1:3d}/{EPOCHS}] | Loss: {avg_loss:.8f} | LR: {current_lr:.6f}")

    print("-" * 70)
    print("âœ… è®­ç»ƒå®Œæˆï¼")

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶å†»ç»“å‚æ•°
    hsi_degen.eval()
    msi_degen.eval()
    for param in hsi_degen.parameters():
        param.requires_grad = False
    for param in msi_degen.parameters():
        param.requires_grad = False

    # ä¿å­˜æƒé‡
    hsi_weight_path = os.path.join(WEIGHT_SAVE_PATH, "deep_hsi_degen_32x.pth")
    msi_weight_path = os.path.join(WEIGHT_SAVE_PATH, "deep_msi_degen_3band.pth")

    torch.save(hsi_degen.state_dict(), hsi_weight_path)
    torch.save(msi_degen.state_dict(), msi_weight_path)

    print(f"ğŸ’¾ HSIé€€åŒ–ç½‘ç»œæƒé‡å·²ä¿å­˜: {hsi_weight_path}")
    print(f"ğŸ’¾ MSIé€€åŒ–ç½‘ç»œæƒé‡å·²ä¿å­˜: {msi_weight_path}")
    print("=" * 70 + "\n")

    return hsi_degen, msi_degen


# ====================== 10. æ‰¹é‡ç”Ÿæˆé…å¯¹æ•°æ® ======================
def generate_deformed_pair_data(gt_input_dir, hsi_save_dir, msi_save_dir, desc, hsi_degen, msi_degen):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„é€€åŒ–ç½‘ç»œæ‰¹é‡ç”ŸæˆHSI/MSIé…å¯¹æ•°æ®

    Args:
        gt_input_dir: GTå›¾åƒè¾“å…¥ç›®å½•
        hsi_save_dir: HSIè¾“å‡ºç›®å½•
        msi_save_dir: MSIè¾“å‡ºç›®å½•
        desc: æè¿°ä¿¡æ¯
        hsi_degen: HSIé€€åŒ–ç½‘ç»œ
        msi_degen: MSIé€€åŒ–ç½‘ç»œ
    """
    print("\n" + "=" * 70)
    print(f"ğŸ”¥ ç”Ÿæˆ {desc}")
    print("=" * 70)
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {gt_input_dir}")
    print(f"ğŸ“‚ HSIè¾“å‡º:  {hsi_save_dir}")
    print(f"ğŸ“‚ MSIè¾“å‡º:  {msi_save_dir}")
    print("-" * 70)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(hsi_save_dir, exist_ok=True)
    os.makedirs(msi_save_dir, exist_ok=True)

    # æŸ¥æ‰¾GTæ–‡ä»¶
    valid_suffix = ['.mat', '.MAT']
    gt_file_paths = sorted([p for p in Path(gt_input_dir).glob("*.*") if p.suffix in valid_suffix])

    if len(gt_file_paths) == 0:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»»ä½•.matæ–‡ä»¶ï¼")
        return

    print(f"âœ… æ‰¾åˆ° {len(gt_file_paths)} å¼ GTå›¾åƒ")

    success_count = 0

    with torch.no_grad():
        for idx, gt_path in enumerate(gt_file_paths):
            fname = gt_path.name

            try:
                # åŠ è½½GT
                gt_np = load_mat_data(gt_path)  # (31, 512, 512)
                gt_tensor = torch.from_numpy(gt_np).unsqueeze(0).to(DEVICE)

                # ç¬¬ä¸€ä¸ªæ ·æœ¬æ—¶æ‰“å°ç»´åº¦
                if idx == 0:
                    print(f"âœ… GTç»´åº¦: {gt_tensor.shape} â†’ æ ‡å‡†æ ¼å¼ [1, 31, 512, 512] âœ”ï¸")

                # ç”ŸæˆHSIå’ŒMSI
                hsi_tensor = hsi_degen(gt_tensor)  # (1, 31, 16, 16)
                msi_tensor = msi_degen(gt_tensor)  # (1, 3, 512, 512)

                # è½¬æ¢ä¸ºnumpyå¹¶ä¿å­˜
                hsi_np = hsi_tensor.squeeze(0).cpu().numpy()
                msi_np = msi_tensor.squeeze(0).cpu().numpy()

                sio.savemat(os.path.join(hsi_save_dir, fname), {'data': hsi_np})
                sio.savemat(os.path.join(msi_save_dir, fname), {'data': msi_np})

                success_count += 1

                # æ¸…ç†å†…å­˜
                del gt_tensor, hsi_tensor, msi_tensor, gt_np, hsi_np, msi_np
                gc.collect()

                # æ‰“å°è¿›åº¦
                if (idx + 1) % 5 == 0 or (idx + 1) == len(gt_file_paths):
                    print(f"è¿›åº¦: {idx + 1}/{len(gt_file_paths)} å¼ ï¼ŒæˆåŠŸ {success_count} å¼ ")

            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {fname}: {str(e)}")
                continue

    print("-" * 70)
    print(f"âœ… {desc} ç”Ÿæˆå®Œæˆï¼")
    print(f"âœ… æˆåŠŸç”Ÿæˆ {success_count}/{len(gt_file_paths)} ç»„é…å¯¹æ•°æ®")
    print("=" * 70 + "\n")


# ====================== 11. ä¸»å‡½æ•° ======================
if __name__ == "__main__":
    print("\n" + "ğŸ¯ " * 35)
    print("å¼€å§‹æ‰§è¡Œ MulFS-CAP HSI-MSI æ•°æ®ç”Ÿæˆæµç¨‹")
    print("ğŸ¯ " * 35 + "\n")

    # ========== æ–¹å¼1: è®­ç»ƒé€€åŒ–ç½‘ç»œï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä½¿ç”¨ï¼‰==========
    # å¦‚æœä½ è¿˜æ²¡æœ‰è®­ç»ƒè¿‡é€€åŒ–ç½‘ç»œï¼Œå–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Š
    hsi_degen, msi_degen = train_deep_degenerators()

    # ========== æ–¹å¼2: åŠ è½½å·²è®­ç»ƒçš„æƒé‡ï¼ˆæ¨èï¼‰==========
    # å¦‚æœä½ å·²ç»è®­ç»ƒè¿‡ï¼Œç›´æ¥åŠ è½½æƒé‡
    print("=" * 70)
    print("ğŸ“¦ åŠ è½½é¢„è®­ç»ƒçš„é€€åŒ–ç½‘ç»œæƒé‡")
    print("=" * 70)

    hsi_weight_path = os.path.join(WEIGHT_SAVE_PATH, "deep_hsi_degen_32x.pth")
    msi_weight_path = os.path.join(WEIGHT_SAVE_PATH, "deep_msi_degen_3band.pth")

    # æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(hsi_weight_path) or not os.path.exists(msi_weight_path):
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒæµç¨‹ï¼ˆå–æ¶ˆä¸»å‡½æ•°ä¸­çš„è®­ç»ƒä»£ç æ³¨é‡Šï¼‰")
        print(f"æœŸæœ›è·¯å¾„: {hsi_weight_path}")
        print(f"æœŸæœ›è·¯å¾„: {msi_weight_path}")
        exit(1)

    # åˆå§‹åŒ–ç½‘ç»œ
    hsi_degen = DeepHSIDegenerator(GT_BANDS, GT_BANDS, DOWNSAMPLE_SCALE).to(DEVICE)
    msi_degen = DeepMSIDegenerator(GT_BANDS, MSI_BANDS).to(DEVICE)

    # åŠ è½½æƒé‡
    hsi_degen.load_state_dict(torch.load(hsi_weight_path))
    msi_degen.load_state_dict(torch.load(msi_weight_path))

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    hsi_degen.eval()
    msi_degen.eval()
    for param in hsi_degen.parameters():
        param.requires_grad = False
    for param in msi_degen.parameters():
        param.requires_grad = False

    print(f"âœ… HSIé€€åŒ–ç½‘ç»œæƒé‡å·²åŠ è½½: {hsi_weight_path}")
    print(f"âœ… MSIé€€åŒ–ç½‘ç»œæƒé‡å·²åŠ è½½: {msi_weight_path}")
    print("=" * 70 + "\n")

    # ========== ç”Ÿæˆé…å¯¹æ•°æ® ==========
    # 1ï¸âƒ£ ä»åŸå§‹GTç”Ÿæˆé‡å»ºçš„HSIå’ŒMSIï¼ˆPair 1: åŸå§‹é…å‡†å¯¹ï¼‰
    generate_deformed_pair_data(
        GT_RAW_DIR,  # è¾“å…¥: X/ (åŸå§‹GT)
        Z_RECONST_SAVE,  # è¾“å‡º: Z_reconst/ (é‡å»ºHSI)
        Y_RECONST_SAVE,  # è¾“å‡º: Y_reconst/ (é‡å»ºMSI)
        "Pair 1 é…å‡†æ•°æ® (Z_reconst + Y_reconst)",
        hsi_degen,
        msi_degen
    )

    # 2ï¸âƒ£ ä»å½¢å˜GTç”Ÿæˆå½¢å˜çš„HSIå’ŒMSIï¼ˆPair 2: å½¢å˜é…å‡†å¯¹ï¼‰
    generate_deformed_pair_data(
        GT_DEFORMED_DIR,  # è¾“å…¥: X_deformed/ (å½¢å˜GT)
        HSI_DEFORMED_SAVE,  # è¾“å‡º: Z_deformed/ (å½¢å˜HSI)
        MSI_DEFORMED_SAVE,  # è¾“å‡º: Y_deformed/ (å½¢å˜MSI)
        "Pair 2 é…å‡†æ•°æ® (Z_deformed + Y_deformed)",
        hsi_degen,
        msi_degen
    )

    # ========== æœ€ç»ˆæ€»ç»“ ==========
    print("\n" + "ğŸ‰ " * 35)
    print("æ‰€æœ‰æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("ğŸ‰ " * 35 + "\n")

    print("=" * 70)
    print("ğŸ“Š æœ€ç»ˆæ•°æ®ç»“æ„:")
    print("=" * 70)
    print(f"âœ… Pair 1 (åŸå§‹é…å‡†å¯¹):")
    print(f"   - HSI: {Z_RECONST_SAVE}")
    print(f"   - MSI: {Y_RECONST_SAVE}")
    print(f"   - GT:  {GT_RAW_DIR}")
    print()
    print(f"âœ… Pair 2 (å½¢å˜é…å‡†å¯¹):")
    print(f"   - HSI: {HSI_DEFORMED_SAVE}")
    print(f"   - MSI: {MSI_DEFORMED_SAVE}")
    print(f"   - GT:  {GT_DEFORMED_DIR}")
    print("=" * 70)
    print()
    print("ğŸš€ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ train.py å¼€å§‹è®­ç»ƒ MulFS-CAPï¼")
    print("=" * 70 + "\n")